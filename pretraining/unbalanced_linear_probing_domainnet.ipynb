{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import random\n",
    "import json\n",
    "\n",
    "from data_modules.domainnet_dataset import ImageDataset\n",
    "from data_modules.domainnet_metadata import DOMAIN_NET_DOMAINS, DOMAIN_NET_CLASSES, DOMAIN_NET_DIVISIONS\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "from yasin_utils.image import imagenet_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_map = {}\n",
    "for k, v in DOMAIN_NET_DIVISIONS.items():\n",
    "    for i in v:\n",
    "        division_map[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/data/domainnet_v1.0'\n",
    "# set_map = []\n",
    "# for domain in DOMAIN_NET_DOMAINS:\n",
    "#     try:\n",
    "#         labels = os.listdir(os.path.join(root, domain))\n",
    "#     except:\n",
    "#         raise Exception(f'{domain} directory not found.')\n",
    "#     for label in labels:\n",
    "#         for image in os.listdir(os.path.join(root, domain, label)):\n",
    "#             if label in division_map:\n",
    "#                 set_map.append(\n",
    "#                     dict(\n",
    "#                         img_path=os.path.join(root, domain, label, image),\n",
    "#                         label=division_map[label],\n",
    "#                         domain=domain\n",
    "#                         )\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(set_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_map, test_set_map = set_map[:int(0.9*len(set_map))], set_map[int(0.9*len(set_map)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/yasin/repos/dispatch_smol/pretraining/data_modules/train_set_map_domainnet.json') as f:\n",
    "    train_set_map_ = json.load(f)\n",
    "with open('/home/yasin/repos/dispatch_smol/pretraining/data_modules/test_set_map_domainnet.json') as f:\n",
    "    test_set_map_ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_map = []\n",
    "for sample in train_set_map_:\n",
    "    if sample['label'] in division_map:\n",
    "        new_sample = {**sample}\n",
    "        new_sample['label'] = division_map[sample['label']]\n",
    "        train_set_map.append(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_map = []\n",
    "for sample in test_set_map_:\n",
    "    if sample['label'] in division_map:\n",
    "        new_sample = {**sample}\n",
    "        new_sample['label'] = division_map[sample['label']]\n",
    "        test_set_map.append(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241485, 26659)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set_map), len(test_set_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tool', 'quickdraw'): 12600,\n",
       " ('tool', 'painting'): 4618,\n",
       " ('electricity', 'real'): 10563,\n",
       " ('cloth', 'infograph'): 3370,\n",
       " ('tool', 'real'): 11645,\n",
       " ('mammal', 'quickdraw'): 11309,\n",
       " ('cloth', 'real'): 10397,\n",
       " ('tool', 'clipart'): 3441,\n",
       " ('mammal', 'sketch'): 4644,\n",
       " ('electricity', 'painting'): 2669,\n",
       " ('furniture', 'painting'): 4472,\n",
       " ('cloth', 'painting'): 3192,\n",
       " ('furniture', 'sketch'): 6760,\n",
       " ('building', 'quickdraw'): 9479,\n",
       " ('furniture', 'real'): 15417,\n",
       " ('building', 'real'): 10874,\n",
       " ('mammal', 'clipart'): 3096,\n",
       " ('furniture', 'quickdraw'): 15745,\n",
       " ('mammal', 'infograph'): 3212,\n",
       " ('mammal', 'real'): 13996,\n",
       " ('electricity', 'infograph'): 3744,\n",
       " ('electricity', 'quickdraw'): 11284,\n",
       " ('cloth', 'sketch'): 4374,\n",
       " ('building', 'painting'): 4610,\n",
       " ('mammal', 'painting'): 8114,\n",
       " ('electricity', 'clipart'): 2803,\n",
       " ('cloth', 'clipart'): 3275,\n",
       " ('building', 'sketch'): 4241,\n",
       " ('furniture', 'clipart'): 5199,\n",
       " ('tool', 'sketch'): 4373,\n",
       " ('cloth', 'quickdraw'): 10285,\n",
       " ('building', 'clipart'): 2495,\n",
       " ('building', 'infograph'): 2840,\n",
       " ('furniture', 'infograph'): 5861,\n",
       " ('electricity', 'sketch'): 3683,\n",
       " ('tool', 'infograph'): 2805}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(collections.Counter([(d['label'], d['domain']) for d in train_set_map]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_map = {\n",
    "#     'furniture': {'main_domain': 'clipart', 'target': 5_253},\n",
    "#     'cloth': {'main_domain': 'real', 'target': 10_377},\n",
    "#     'electricity': {'main_domain': 'infograph', 'target': 3_745},\n",
    "#     'building': {'main_domain': 'painting', 'target': 4_570},\n",
    "#     'mammal': {'main_domain': 'quickdraw', 'target': 11_202},\n",
    "#     'tool': {'main_domain': 'sketch', 'target': 4_401},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_map = {\n",
    "    'furniture': {'main_domain': 'clipart', 'target': 1_000},\n",
    "    'cloth': {'main_domain': 'real', 'target': 1_000},\n",
    "    'electricity': {'main_domain': 'infograph', 'target': 1_000},\n",
    "    'building': {'main_domain': 'painting', 'target': 1_000},\n",
    "    'mammal': {'main_domain': 'quickdraw', 'target': 1_000},\n",
    "    'tool': {'main_domain': 'sketch', 'target': 1_000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_map = {\n",
    "#     'furniture': {'main_domain': 'clipart', 'target': 1_000},\n",
    "#     'cloth': {'main_domain': 'real', 'target': 1_000},\n",
    "#     'electricity': {'main_domain': 'infograph', 'target': 1_000},\n",
    "#     'building': {'main_domain': 'painting', 'target': 1_000},\n",
    "#     'mammal': {'main_domain': 'quickdraw', 'target': 1_000},\n",
    "#     'tool': {'main_domain': 'sketch', 'target': 1_000},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_map = {\n",
    "#     'furniture': {'main_domain': 'clipart', 'target': 100},\n",
    "#     'cloth': {'main_domain': 'real', 'target': 100},\n",
    "#     'electricity': {'main_domain': 'infograph', 'target': 100},\n",
    "#     'building': {'main_domain': 'painting', 'target': 100},\n",
    "#     'mammal': {'main_domain': 'quickdraw', 'target': 100},\n",
    "#     'tool': {'main_domain': 'sketch', 'target': 100},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(set_map, balance_map):\n",
    "    pruned_set_map = []\n",
    "    \n",
    "    domains = set([i['domain'] for i in set_map])\n",
    "    counts = {\n",
    "        l: {\n",
    "            d: 0 for d in domains\n",
    "        } for l in balance_map\n",
    "    }\n",
    "    targets = {\n",
    "        l: {\n",
    "            d: balance_map[l]['target'] if d == balance_map[l]['main_domain'] else int(balance_map[l]['target']*0.066) for d in domains\n",
    "        } for l in balance_map\n",
    "    }\n",
    "\n",
    "    for i in set_map:\n",
    "        label, domain = i['label'], i['domain']\n",
    "\n",
    "        if counts[label][domain] < targets[label][domain]:\n",
    "            pruned_set_map.append(i)\n",
    "\n",
    "        counts[label][domain] += 1\n",
    "\n",
    "    return pruned_set_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_map = prune(train_set_map, balance_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tool', 'quickdraw'): 66,\n",
       " ('tool', 'painting'): 66,\n",
       " ('electricity', 'real'): 66,\n",
       " ('cloth', 'infograph'): 66,\n",
       " ('tool', 'real'): 66,\n",
       " ('mammal', 'quickdraw'): 1000,\n",
       " ('cloth', 'real'): 1000,\n",
       " ('tool', 'clipart'): 66,\n",
       " ('mammal', 'sketch'): 66,\n",
       " ('electricity', 'painting'): 66,\n",
       " ('furniture', 'painting'): 66,\n",
       " ('cloth', 'painting'): 66,\n",
       " ('furniture', 'sketch'): 66,\n",
       " ('building', 'quickdraw'): 66,\n",
       " ('furniture', 'real'): 66,\n",
       " ('building', 'real'): 66,\n",
       " ('mammal', 'clipart'): 66,\n",
       " ('furniture', 'quickdraw'): 66,\n",
       " ('mammal', 'infograph'): 66,\n",
       " ('mammal', 'real'): 66,\n",
       " ('electricity', 'infograph'): 1000,\n",
       " ('electricity', 'quickdraw'): 66,\n",
       " ('cloth', 'sketch'): 66,\n",
       " ('building', 'painting'): 1000,\n",
       " ('mammal', 'painting'): 66,\n",
       " ('electricity', 'clipart'): 66,\n",
       " ('cloth', 'clipart'): 66,\n",
       " ('building', 'sketch'): 66,\n",
       " ('furniture', 'clipart'): 1000,\n",
       " ('tool', 'sketch'): 1000,\n",
       " ('cloth', 'quickdraw'): 66,\n",
       " ('building', 'clipart'): 66,\n",
       " ('building', 'infograph'): 66,\n",
       " ('furniture', 'infograph'): 66,\n",
       " ('electricity', 'sketch'): 66,\n",
       " ('tool', 'infograph'): 66}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(collections.Counter([(d['label'], d['domain']) for d in train_set_map]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnbalancedDomainNetDataset(ImageDataset):\n",
    "    def __init__(self, set_map, transform=None) -> None:\n",
    "\n",
    "        super().__init__(set_map, transform)\n",
    "        self.class_map = {\n",
    "            'furniture': 0,\n",
    "            'cloth': 1,\n",
    "            'electricity': 2,\n",
    "            'building': 3,\n",
    "            'mammal': 4,\n",
    "            'tool': 5,\n",
    "        }\n",
    "        self.domain_map = {\n",
    "            'clipart': 0,\n",
    "            'real': 1,\n",
    "            'infograph': 2,\n",
    "            'painting': 3,\n",
    "            'quickdraw': 4,\n",
    "            'sketch': 5,\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = super().__getitem__(index)\n",
    "        item['label'] = self.class_map[item['label']]\n",
    "        item['domain'] = self.domain_map[item['domain']]\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_transform = T.Compose([\n",
    "    T.RandomResizedCrop(128),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    # T.Resize((128,128)),\n",
    "    T.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    T.Resize(156),\n",
    "    T.CenterCrop(128),\n",
    "    # T.Resize((128,128)),\n",
    "    T.ToTensor(),\n",
    "    imagenet_normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = UnbalancedDomainNetDataset(set_map=train_set_map, transform=train_transform)\n",
    "test_set = UnbalancedDomainNetDataset(set_map=test_set_map, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=8, pin_memory=True, persistent_workers=True, drop_last=True)\n",
    "val_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7980, 26659)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet50\n",
    "import pytorch_lightning as L\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(L.LightningModule):\n",
    "    def __init__(self, backbone, emb_dim, num_classes, lr=1e-3) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone: nn.Module = backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.backbone.eval()\n",
    "\n",
    "        # self.linear_head: nn.Module = nn.Linear(emb_dim, num_classes)\n",
    "        self.linear_head: nn.Module = nn.Sequential(\n",
    "            nn.Linear(emb_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Linear(512, num_classes)\n",
    "        ) \n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.test_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.linear_head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, bacth_idx):\n",
    "        X = batch['image']\n",
    "        t = batch['label']\n",
    "\n",
    "        y = self.forward(X)\n",
    "        loss = self.criterion(y, t)\n",
    "\n",
    "        print(loss.item())\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X = batch['image']\n",
    "        t = batch['label']\n",
    "\n",
    "        y = self.forward(X)\n",
    "        acc = self.test_accuracy(y, t)\n",
    "\n",
    "        self.log('accuracy', acc, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.linear_head.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 20)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_from_ckpt(ckpt_path: str) -> torch.nn.Module:\n",
    "    state_dict = torch.load(ckpt_path)[\"state_dict\"]\n",
    "    state_dict = OrderedDict([\n",
    "        (\".\".join(name.split(\".\")[1:]), param) for name, param in state_dict.items() if name.startswith(\"backbone\")\n",
    "    ])\n",
    "\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "model_bl  = resnet50()\n",
    "weights_bl = get_backbone_from_ckpt(\"/home/yasin/Downloads/final_baseline.ckpt\")\n",
    "model_bl.load_state_dict(weights_bl, strict=False)\n",
    "model_bl.fc = torch.nn.Identity()\n",
    "model_bl = model_bl.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MixStyle Model\n",
    "model_ms  = resnet50()\n",
    "weights_ms = get_backbone_from_ckpt(\"/home/yasin/Downloads/final_mixstyle.ckpt\")\n",
    "model_ms.load_state_dict(weights_ms, strict=False)\n",
    "model_ms.fc = torch.nn.Identity()\n",
    "model_ms = model_ms.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_module = LinearProbe(model_bl, emb_dim=2048, num_classes=6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixstyle_module = LinearProbe(model_ms, emb_dim=2048, num_classes=6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | backbone      | ResNet             | 23.5 M\n",
      "1 | linear_head   | Sequential         | 2.6 M \n",
      "2 | criterion     | CrossEntropyLoss   | 0     \n",
      "3 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "26.1 M    Total params\n",
      "104.536   Total estimated model params size (MB)\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c2dc58b8db419db7100db200eb8c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7810397148132324\n",
      "1.36961829662323\n",
      "1.092119812965393\n",
      "0.9771843552589417\n",
      "1.1575037240982056\n",
      "0.7649868130683899\n",
      "0.7838195562362671\n",
      "0.9604010581970215\n",
      "0.7803102135658264\n",
      "0.7661674618721008\n",
      "0.8221171498298645\n",
      "0.6671039462089539\n",
      "0.7189761996269226\n",
      "0.6239356398582458\n",
      "0.7182053327560425\n",
      "0.7173534631729126\n",
      "0.6342187523841858\n",
      "0.5578938126564026\n",
      "0.5405734181404114\n",
      "0.7385568022727966\n",
      "0.6075434684753418\n",
      "0.5811040997505188\n",
      "0.6606559157371521\n",
      "0.6409361362457275\n",
      "0.4347786605358124\n",
      "0.6261606216430664\n",
      "0.5951897501945496\n",
      "0.6176638007164001\n",
      "0.5955409407615662\n",
      "0.6534581780433655\n",
      "0.7111263275146484\n",
      "0.5203158855438232\n",
      "0.42858952283859253\n",
      "0.49958038330078125\n",
      "0.4297848343849182\n",
      "0.5063486695289612\n",
      "0.4422544240951538\n",
      "0.5310287475585938\n",
      "0.3438812494277954\n",
      "0.47810909152030945\n",
      "0.37852543592453003\n",
      "0.43963780999183655\n",
      "0.42379385232925415\n",
      "0.45459529757499695\n",
      "0.4058496654033661\n",
      "0.5303097367286682\n",
      "0.5427607297897339\n",
      "0.4561728239059448\n",
      "0.4538537263870239\n",
      "0.39242053031921387\n",
      "0.45984452962875366\n",
      "0.49451979994773865\n",
      "0.4154449701309204\n",
      "0.5557947754859924\n",
      "0.5322414636611938\n",
      "0.44119223952293396\n",
      "0.48181185126304626\n",
      "0.49201279878616333\n",
      "0.4509119391441345\n",
      "0.4735983610153198\n",
      "0.44304272532463074\n",
      "0.3794393539428711\n",
      "0.4177568256855011\n",
      "0.323625773191452\n",
      "0.36916470527648926\n",
      "0.3296802043914795\n",
      "0.3346320688724518\n",
      "0.3311590552330017\n",
      "0.3413696885108948\n",
      "0.40434491634368896\n",
      "0.4010438024997711\n",
      "0.3527287244796753\n",
      "0.4064382314682007\n",
      "0.385433167219162\n",
      "0.37648218870162964\n",
      "0.342258095741272\n",
      "0.3528125584125519\n",
      "0.47929176688194275\n",
      "0.3996444344520569\n",
      "0.4339454770088196\n",
      "0.4076122045516968\n",
      "0.34903573989868164\n",
      "0.3120294213294983\n",
      "0.33825820684432983\n",
      "0.2778165638446808\n",
      "0.33480414748191833\n",
      "0.3734113276004791\n",
      "0.2958521246910095\n",
      "0.4549843966960907\n",
      "0.3417506814002991\n",
      "0.3197454810142517\n",
      "0.33525678515434265\n",
      "0.3877207338809967\n",
      "0.29752010107040405\n",
      "0.2895578444004059\n",
      "0.25953230261802673\n",
      "0.3685397207736969\n",
      "0.2895694077014923\n",
      "0.24208049476146698\n",
      "0.24643130600452423\n",
      "0.39425620436668396\n",
      "0.22117742896080017\n",
      "0.25521644949913025\n",
      "0.25838831067085266\n",
      "0.27404549717903137\n",
      "0.33659666776657104\n",
      "0.2854085862636566\n",
      "0.31429678201675415\n",
      "0.2895405888557434\n",
      "0.42768001556396484\n",
      "0.24836422502994537\n",
      "0.29016783833503723\n",
      "0.33388933539390564\n",
      "0.27559345960617065\n",
      "0.34054332971572876\n",
      "0.3461097180843353\n",
      "0.2147935926914215\n",
      "0.3505222797393799\n",
      "0.2656288146972656\n",
      "0.3493645489215851\n",
      "0.35637742280960083\n",
      "0.4126744866371155\n",
      "0.30758941173553467\n",
      "0.2920520007610321\n",
      "0.23911994695663452\n",
      "0.2837039828300476\n",
      "0.2183593362569809\n",
      "0.2311982959508896\n",
      "0.22079186141490936\n",
      "0.24952766299247742\n",
      "0.34373149275779724\n",
      "0.30028611421585083\n",
      "0.24924708902835846\n",
      "0.2645629644393921\n",
      "0.2451857626438141\n",
      "0.20952312648296356\n",
      "0.23519602417945862\n",
      "0.28158238530158997\n",
      "0.2512167692184448\n",
      "0.29305312037467957\n",
      "0.314313679933548\n",
      "0.3186781406402588\n",
      "0.2206241488456726\n",
      "0.23694749176502228\n",
      "0.27550193667411804\n",
      "0.19102047383785248\n",
      "0.2440682202577591\n",
      "0.20095312595367432\n",
      "0.34354278445243835\n",
      "0.2649541199207306\n",
      "0.19933849573135376\n",
      "0.3294389843940735\n",
      "0.26956644654273987\n",
      "0.21890901029109955\n",
      "0.3143177926540375\n",
      "0.1809893399477005\n",
      "0.1894000619649887\n",
      "0.14869630336761475\n",
      "0.2730312645435333\n",
      "0.1702226847410202\n",
      "0.1759062260389328\n",
      "0.19182458519935608\n",
      "0.18044880032539368\n",
      "0.16344474256038666\n",
      "0.2588513493537903\n",
      "0.25895801186561584\n",
      "0.16021740436553955\n",
      "0.24775931239128113\n",
      "0.20262420177459717\n",
      "0.23556926846504211\n",
      "0.22893860936164856\n",
      "0.19214409589767456\n",
      "0.17960968613624573\n",
      "0.21546898782253265\n",
      "0.16845671832561493\n",
      "0.3652060329914093\n",
      "0.26968446373939514\n",
      "0.2688082456588745\n",
      "0.16425612568855286\n",
      "0.20975661277770996\n",
      "0.21790939569473267\n",
      "0.29058027267456055\n",
      "0.2356184870004654\n",
      "0.247329443693161\n",
      "0.20383630692958832\n",
      "0.2587086260318756\n",
      "0.15840335190296173\n",
      "0.26342150568962097\n",
      "0.18442851305007935\n",
      "0.16551558673381805\n",
      "0.15065670013427734\n",
      "0.24849918484687805\n",
      "0.190094456076622\n",
      "0.20499780774116516\n",
      "0.14755012094974518\n",
      "0.27452951669692993\n",
      "0.1584242582321167\n",
      "0.15584251284599304\n",
      "0.18846935033798218\n",
      "0.136159285902977\n",
      "0.2358609288930893\n",
      "0.2575661838054657\n",
      "0.24896036088466644\n",
      "0.2265019714832306\n",
      "0.11792749911546707\n",
      "0.2552735507488251\n",
      "0.20969435572624207\n",
      "0.19070123136043549\n",
      "0.23510561883449554\n",
      "0.2483176290988922\n",
      "0.28066447377204895\n",
      "0.14033082127571106\n",
      "0.24981361627578735\n",
      "0.18043552339076996\n",
      "0.212971493601799\n",
      "0.1627618968486786\n",
      "0.16781505942344666\n",
      "0.1767825484275818\n",
      "0.21377193927764893\n",
      "0.1433643102645874\n",
      "0.12652817368507385\n",
      "0.21149751543998718\n",
      "0.21607649326324463\n",
      "0.13594414293766022\n",
      "0.13391068577766418\n",
      "0.16667070984840393\n",
      "0.08733823895454407\n",
      "0.1972411572933197\n",
      "0.20360270142555237\n",
      "0.11014007031917572\n",
      "0.1285628080368042\n",
      "0.20089121162891388\n",
      "0.19317930936813354\n",
      "0.2559882700443268\n",
      "0.1221725270152092\n",
      "0.1580287516117096\n",
      "0.14229658246040344\n",
      "0.1711132973432541\n",
      "0.17503544688224792\n",
      "0.19603365659713745\n",
      "0.2335619330406189\n",
      "0.18615302443504333\n",
      "0.18458367884159088\n",
      "0.12554223835468292\n",
      "0.17318257689476013\n",
      "0.1330580711364746\n",
      "0.15418741106987\n",
      "0.19733546674251556\n",
      "0.11676706373691559\n",
      "0.15908578038215637\n",
      "0.12951473891735077\n",
      "0.1445351541042328\n",
      "0.12858489155769348\n",
      "0.17215046286582947\n",
      "0.1191519945859909\n",
      "0.18374215066432953\n",
      "0.08307375758886337\n",
      "0.20340369641780853\n",
      "0.1305915117263794\n",
      "0.10810799151659012\n",
      "0.14092914760112762\n",
      "0.18459416925907135\n",
      "0.19387537240982056\n",
      "0.12678755819797516\n",
      "0.2081957459449768\n",
      "0.20524054765701294\n",
      "0.18065913021564484\n",
      "0.1720511019229889\n",
      "0.1663333773612976\n",
      "0.14207594096660614\n",
      "0.18752625584602356\n",
      "0.17529122531414032\n",
      "0.20031088590621948\n",
      "0.20168966054916382\n",
      "0.16609935462474823\n",
      "0.1479591429233551\n",
      "0.11924982070922852\n",
      "0.11089005321264267\n",
      "0.20527313649654388\n",
      "0.21105912327766418\n",
      "0.13854044675827026\n",
      "0.11744587123394012\n",
      "0.18138107657432556\n",
      "0.09080681949853897\n",
      "0.1618451625108719\n",
      "0.12049075961112976\n",
      "0.1368400752544403\n",
      "0.13553112745285034\n",
      "0.10147931426763535\n",
      "0.06770765036344528\n",
      "0.09024462848901749\n",
      "0.17380809783935547\n",
      "0.15886199474334717\n",
      "0.15201471745967865\n",
      "0.09019400924444199\n",
      "0.12778577208518982\n",
      "0.09511153399944305\n",
      "0.10744103044271469\n",
      "0.13179640471935272\n",
      "0.1414281278848648\n",
      "0.13353648781776428\n",
      "0.1147371307015419\n",
      "0.12352023273706436\n",
      "0.134521484375\n",
      "0.15463323891162872\n",
      "0.12433510273694992\n",
      "0.1831599473953247\n",
      "0.1264072209596634\n",
      "0.15631309151649475\n",
      "0.19494381546974182\n",
      "0.08452339470386505\n",
      "0.08550272136926651\n",
      "0.1498161405324936\n",
      "0.08028120547533035\n",
      "0.08769375085830688\n",
      "0.11503434181213379\n",
      "0.1266278326511383\n",
      "0.12040264159440994\n",
      "0.09069864451885223\n",
      "0.12553292512893677\n",
      "0.1235119178891182\n",
      "0.13476766645908356\n",
      "0.08508902788162231\n",
      "0.10902496427297592\n",
      "0.0908714309334755\n",
      "0.13791194558143616\n",
      "0.07626129686832428\n",
      "0.12040982395410538\n",
      "0.08841142058372498\n",
      "0.10347094386816025\n",
      "0.22962678968906403\n",
      "0.10772313922643661\n",
      "0.14810705184936523\n",
      "0.11765517294406891\n",
      "0.12911313772201538\n",
      "0.10731983184814453\n",
      "0.17600585520267487\n",
      "0.14386998116970062\n",
      "0.1015688106417656\n",
      "0.06316916644573212\n",
      "0.1376591920852661\n",
      "0.113221175968647\n",
      "0.14349280297756195\n",
      "0.11185860633850098\n",
      "0.08240991830825806\n",
      "0.08215037733316422\n",
      "0.11071766167879105\n",
      "0.08514364808797836\n",
      "0.09090675413608551\n",
      "0.10279446095228195\n",
      "0.10956578701734543\n",
      "0.11533845216035843\n",
      "0.11222631484270096\n",
      "0.09039492160081863\n",
      "0.12295026332139969\n",
      "0.1575094610452652\n",
      "0.07797796279191971\n",
      "0.09403330832719803\n",
      "0.05195968598127365\n",
      "0.08468010276556015\n",
      "0.06034741923213005\n",
      "0.16115134954452515\n",
      "0.0902618020772934\n",
      "0.10359332710504532\n",
      "0.12597699463367462\n",
      "0.12174708396196365\n",
      "0.07145968079566956\n",
      "0.11854591965675354\n",
      "0.10719829797744751\n",
      "0.06276281923055649\n",
      "0.0928708165884018\n",
      "0.11756455898284912\n",
      "0.11194710433483124\n",
      "0.07015375792980194\n",
      "0.13816571235656738\n",
      "0.13620783388614655\n",
      "0.10559982806444168\n",
      "0.07608047872781754\n",
      "0.12329446524381638\n",
      "0.07885961979627609\n",
      "0.10346709936857224\n",
      "0.07803776115179062\n",
      "0.10292187333106995\n",
      "0.11325384676456451\n",
      "0.11618659645318985\n",
      "0.1008312851190567\n",
      "0.21038863062858582\n",
      "0.14163462817668915\n",
      "0.06645645946264267\n",
      "0.13542895019054413\n",
      "0.1470227837562561\n",
      "0.10232072323560715\n",
      "0.09317602217197418\n",
      "0.05640345811843872\n",
      "0.09337372332811356\n",
      "0.13618740439414978\n",
      "0.10568095743656158\n",
      "0.09034383296966553\n",
      "0.13515214622020721\n",
      "0.08899814635515213\n",
      "0.09917065501213074\n",
      "0.07632127404212952\n",
      "0.17428351938724518\n",
      "0.1421700417995453\n",
      "0.13597728312015533\n",
      "0.07907183468341827\n",
      "0.08372517675161362\n",
      "0.0977710410952568\n",
      "0.09792573750019073\n",
      "0.08607614040374756\n",
      "0.12880700826644897\n",
      "0.11762569844722748\n",
      "0.11796031892299652\n",
      "0.09646027535200119\n",
      "0.07875265926122665\n",
      "0.08645696192979813\n",
      "0.07911141216754913\n",
      "0.11216233670711517\n",
      "0.09014260768890381\n",
      "0.07790139317512512\n",
      "0.12071537971496582\n",
      "0.08084810525178909\n",
      "0.12509243190288544\n",
      "0.13654516637325287\n",
      "0.09930694103240967\n",
      "0.06537874042987823\n",
      "0.0915520116686821\n",
      "0.10847239196300507\n",
      "0.08034340292215347\n",
      "0.1290135234594345\n",
      "0.042561039328575134\n",
      "0.11424042284488678\n",
      "0.09961225837469101\n",
      "0.10731052607297897\n",
      "0.1324641853570938\n",
      "0.09243206679821014\n",
      "0.11526674032211304\n",
      "0.0624876469373703\n",
      "0.05083132162690163\n",
      "0.13411560654640198\n",
      "0.09372491389513016\n",
      "0.12858523428440094\n",
      "0.08638129383325577\n",
      "0.0893828347325325\n",
      "0.09539075195789337\n",
      "0.1165676862001419\n",
      "0.11861403286457062\n",
      "0.12623609602451324\n",
      "0.08682619035243988\n",
      "0.04309434816241264\n",
      "0.06083296239376068\n",
      "0.16779370605945587\n",
      "0.06879416853189468\n",
      "0.08158298581838608\n",
      "0.09552399069070816\n",
      "0.12112601846456528\n",
      "0.11166871339082718\n",
      "0.08529955893754959\n",
      "0.10191928595304489\n",
      "0.10070131719112396\n",
      "0.06654535979032516\n",
      "0.06628149002790451\n",
      "0.0830843448638916\n",
      "0.09456675499677658\n",
      "0.08296150714159012\n",
      "0.12816773355007172\n",
      "0.0732329934835434\n",
      "0.07162969559431076\n",
      "0.049701593816280365\n",
      "0.09364194422960281\n",
      "0.12283944338560104\n",
      "0.10772448778152466\n",
      "0.0986032485961914\n",
      "0.12667815387248993\n",
      "0.11356180906295776\n",
      "0.04588301107287407\n",
      "0.03988804668188095\n",
      "0.08979768306016922\n",
      "0.09568371623754501\n",
      "0.047729991376399994\n",
      "0.08438736945390701\n",
      "0.03636380285024643\n",
      "0.08730089664459229\n",
      "0.05355241149663925\n",
      "0.07156412303447723\n",
      "0.10944454371929169\n",
      "0.05214625224471092\n",
      "0.10774840414524078\n",
      "0.12685321271419525\n",
      "0.11922705918550491\n",
      "0.08030318468809128\n",
      "0.10328496992588043\n",
      "0.08898936957120895\n",
      "0.09378567337989807\n",
      "0.07546524703502655\n",
      "0.08937937021255493\n",
      "0.0936632752418518\n",
      "0.1213281899690628\n",
      "0.05272107198834419\n",
      "0.11588334292173386\n",
      "0.09041261672973633\n",
      "0.039887093007564545\n",
      "0.05460565164685249\n",
      "0.08507855236530304\n",
      "0.06403794884681702\n",
      "0.0929441899061203\n",
      "0.07731243222951889\n",
      "0.04458802938461304\n",
      "0.0641065463423729\n",
      "0.1412958949804306\n",
      "0.06074190512299538\n",
      "0.08404450118541718\n",
      "0.09912291169166565\n",
      "0.0926688015460968\n",
      "0.071891650557518\n",
      "0.09574712067842484\n",
      "0.08056117594242096\n",
      "0.11351552605628967\n",
      "0.06412317603826523\n",
      "0.055961187928915024\n",
      "0.10230402648448944\n",
      "0.08309328556060791\n",
      "0.07956238090991974\n",
      "0.08937033265829086\n",
      "0.0650760754942894\n",
      "0.10856448858976364\n",
      "0.0627780556678772\n",
      "0.08345682173967361\n",
      "0.1182091161608696\n",
      "0.07632961124181747\n",
      "0.09544727951288223\n",
      "0.11816757172346115\n",
      "0.028692621737718582\n",
      "0.09597118198871613\n",
      "0.10117287188768387\n",
      "0.06085905805230141\n",
      "0.08285019546747208\n",
      "0.059488777071237564\n",
      "0.06982943415641785\n",
      "0.13417191803455353\n",
      "0.04426903277635574\n",
      "0.13295473158359528\n",
      "0.11182479560375214\n",
      "0.12650486826896667\n",
      "0.058946944773197174\n",
      "0.09128674864768982\n",
      "0.11519832164049149\n",
      "0.079170823097229\n",
      "0.10953380167484283\n",
      "0.054005999118089676\n",
      "0.15928804874420166\n",
      "0.0585004985332489\n",
      "0.05729370191693306\n",
      "0.08372917771339417\n",
      "0.06632833182811737\n",
      "0.045053839683532715\n",
      "0.06730246543884277\n",
      "0.09911064058542252\n",
      "0.1078898012638092\n",
      "0.034792400896549225\n",
      "0.022170303389430046\n",
      "0.07553782314062119\n",
      "0.06529761105775833\n",
      "0.09218459576368332\n",
      "0.09311187267303467\n",
      "0.08703304082155228\n",
      "0.1322927325963974\n",
      "0.07306597381830215\n",
      "0.06279517710208893\n",
      "0.15159735083580017\n",
      "0.05065852403640747\n",
      "0.0854702889919281\n",
      "0.05970911681652069\n",
      "0.07093732059001923\n",
      "0.09069536626338959\n",
      "0.07188086956739426\n",
      "0.06999149173498154\n",
      "0.07991912215948105\n",
      "0.059012528508901596\n",
      "0.06472378969192505\n",
      "0.03987717255949974\n",
      "0.05773085728287697\n",
      "0.06077241897583008\n",
      "0.09524563699960709\n",
      "0.05393538624048233\n",
      "0.07846628129482269\n",
      "0.056742168962955475\n",
      "0.1526307314634323\n",
      "0.077110156416893\n",
      "0.11613481491804123\n",
      "0.07005458325147629\n",
      "0.07911549508571625\n",
      "0.1365552544593811\n",
      "0.05042581632733345\n",
      "0.10328463464975357\n",
      "0.11572667956352234\n",
      "0.09936098009347916\n",
      "0.04527849704027176\n",
      "0.07924205809831619\n",
      "0.10312995314598083\n",
      "0.08105344325304031\n",
      "0.11431397497653961\n",
      "0.09019938111305237\n",
      "0.05599696561694145\n",
      "0.06131518632173538\n",
      "0.10740074515342712\n",
      "0.12197300046682358\n",
      "0.044441524893045425\n",
      "0.09463082253932953\n",
      "0.0797891765832901\n",
      "0.11769280582666397\n",
      "0.057441145181655884\n",
      "0.04765870422124863\n",
      "0.06074831634759903\n",
      "0.05147530883550644\n",
      "0.07267533987760544\n",
      "0.08884298801422119\n",
      "0.05098293349146843\n",
      "0.10294415056705475\n",
      "0.12006835639476776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(baseline_module, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7de344c562c49828e20abcb77b80ffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9746723771095276     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9746723771095276    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.9746723771095276}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(baseline_module, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e3c1d622d448a7a64d1d2ed47babe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6509246230125427     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6509246230125427    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.6509246230125427}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(baseline_module, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | backbone      | ResNet             | 23.5 M\n",
      "1 | linear_head   | Sequential         | 2.6 M \n",
      "2 | criterion     | CrossEntropyLoss   | 0     \n",
      "3 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "2.6 M     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "26.1 M    Total params\n",
      "104.536   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765fb7db9a744afba7affeb320ea9b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7986332178115845\n",
      "1.4751585721969604\n",
      "1.2799625396728516\n",
      "0.9796953797340393\n",
      "0.9334206581115723\n",
      "1.0470263957977295\n",
      "0.9256604313850403\n",
      "0.8343527913093567\n",
      "0.8923870325088501\n",
      "0.6709699630737305\n",
      "0.7703192234039307\n",
      "0.6284136176109314\n",
      "0.6094647645950317\n",
      "0.7093690037727356\n",
      "0.7612224221229553\n",
      "0.6368738412857056\n",
      "0.7426074147224426\n",
      "0.6728995442390442\n",
      "0.6441876888275146\n",
      "0.6590206027030945\n",
      "0.6148056387901306\n",
      "0.6481024622917175\n",
      "0.5634718537330627\n",
      "0.6407226920127869\n",
      "0.6121946573257446\n",
      "0.6580390334129333\n",
      "0.6400423645973206\n",
      "0.7136390805244446\n",
      "0.7540711760520935\n",
      "0.5461564064025879\n",
      "0.6755139827728271\n",
      "0.5839467644691467\n",
      "0.43427425622940063\n",
      "0.49279189109802246\n",
      "0.44395923614501953\n",
      "0.569694995880127\n",
      "0.5148242712020874\n",
      "0.6528785228729248\n",
      "0.5505921244621277\n",
      "0.5004514455795288\n",
      "0.48739388585090637\n",
      "0.510646641254425\n",
      "0.43017762899398804\n",
      "0.4430086016654968\n",
      "0.3902919888496399\n",
      "0.39890602231025696\n",
      "0.4369608759880066\n",
      "0.5540887713432312\n",
      "0.47420623898506165\n",
      "0.5352665185928345\n",
      "0.47310903668403625\n",
      "0.44971928000450134\n",
      "0.4652644991874695\n",
      "0.39026784896850586\n",
      "0.5388175845146179\n",
      "0.441690057516098\n",
      "0.4605535566806793\n",
      "0.5396618843078613\n",
      "0.6225316524505615\n",
      "0.5383835434913635\n",
      "0.45363739132881165\n",
      "0.4850054979324341\n",
      "0.40678948163986206\n",
      "0.45131251215934753\n",
      "0.45841893553733826\n",
      "0.41986221075057983\n",
      "0.4102522134780884\n",
      "0.37457650899887085\n",
      "0.3899165391921997\n",
      "0.38331112265586853\n",
      "0.45741552114486694\n",
      "0.46642616391181946\n",
      "0.39714717864990234\n",
      "0.3666265904903412\n",
      "0.3777356445789337\n",
      "0.3786243796348572\n",
      "0.44997942447662354\n",
      "0.37784162163734436\n",
      "0.38984912633895874\n",
      "0.3892262279987335\n",
      "0.4406455159187317\n",
      "0.47996142506599426\n",
      "0.42427384853363037\n",
      "0.4815711975097656\n",
      "0.435206800699234\n",
      "0.3753560185432434\n",
      "0.35292184352874756\n",
      "0.42681050300598145\n",
      "0.39956143498420715\n",
      "0.42692211270332336\n",
      "0.40062272548675537\n",
      "0.4264049828052521\n",
      "0.4070795774459839\n",
      "0.3644392788410187\n",
      "0.361139714717865\n",
      "0.3189491629600525\n",
      "0.39878231287002563\n",
      "0.3905634582042694\n",
      "0.41761547327041626\n",
      "0.280498743057251\n",
      "0.359634667634964\n",
      "0.35544246435165405\n",
      "0.3621641993522644\n",
      "0.34500545263290405\n",
      "0.3440267741680145\n",
      "0.2778249680995941\n",
      "0.32677632570266724\n",
      "0.3619232475757599\n",
      "0.3862091898918152\n",
      "0.39183753728866577\n",
      "0.322461873292923\n",
      "0.2787609398365021\n",
      "0.33645099401474\n",
      "0.3879227042198181\n",
      "0.315416544675827\n",
      "0.3421974778175354\n",
      "0.3158458173274994\n",
      "0.33565470576286316\n",
      "0.39181894063949585\n",
      "0.3983532786369324\n",
      "0.38138896226882935\n",
      "0.35243427753448486\n",
      "0.33537542819976807\n",
      "0.4105496108531952\n",
      "0.3378573954105377\n",
      "0.2346028834581375\n",
      "0.2598569691181183\n",
      "0.29022151231765747\n",
      "0.25446218252182007\n",
      "0.31230729818344116\n",
      "0.25595715641975403\n",
      "0.35925984382629395\n",
      "0.28558769822120667\n",
      "0.26928266882896423\n",
      "0.29800620675086975\n",
      "0.2646128833293915\n",
      "0.35645806789398193\n",
      "0.2518317699432373\n",
      "0.2996283173561096\n",
      "0.35269734263420105\n",
      "0.2245267778635025\n",
      "0.35003140568733215\n",
      "0.3507179915904999\n",
      "0.29942211508750916\n",
      "0.34267041087150574\n",
      "0.29462453722953796\n",
      "0.25410574674606323\n",
      "0.26484933495521545\n",
      "0.39227819442749023\n",
      "0.36584028601646423\n",
      "0.32778051495552063\n",
      "0.30622291564941406\n",
      "0.29120293259620667\n",
      "0.3410193920135498\n",
      "0.2632521390914917\n",
      "0.2957247495651245\n",
      "0.23076561093330383\n",
      "0.255195289850235\n",
      "0.2725112736225128\n",
      "0.28919821977615356\n",
      "0.235137939453125\n",
      "0.244455948472023\n",
      "0.24789203703403473\n",
      "0.22578294575214386\n",
      "0.23588669300079346\n",
      "0.2697053849697113\n",
      "0.3130158483982086\n",
      "0.19383181631565094\n",
      "0.2755766212940216\n",
      "0.3046475946903229\n",
      "0.2831737697124481\n",
      "0.16808532178401947\n",
      "0.3646541237831116\n",
      "0.29483431577682495\n",
      "0.253828227519989\n",
      "0.2586205303668976\n",
      "0.23888011276721954\n",
      "0.24720224738121033\n",
      "0.27857497334480286\n",
      "0.24792234599590302\n",
      "0.2864137887954712\n",
      "0.23152731359004974\n",
      "0.26171964406967163\n",
      "0.27862387895584106\n",
      "0.26960060000419617\n",
      "0.31346696615219116\n",
      "0.2022055983543396\n",
      "0.24374964833259583\n",
      "0.23372527956962585\n",
      "0.23618100583553314\n",
      "0.1607600897550583\n",
      "0.27588292956352234\n",
      "0.27963000535964966\n",
      "0.1856369823217392\n",
      "0.2661069929599762\n",
      "0.22568178176879883\n",
      "0.21034717559814453\n",
      "0.19964499771595\n",
      "0.18753381073474884\n",
      "0.23131488263607025\n",
      "0.25008922815322876\n",
      "0.21599625051021576\n",
      "0.3624263107776642\n",
      "0.3007141351699829\n",
      "0.2842324674129486\n",
      "0.2880914509296417\n",
      "0.23116984963417053\n",
      "0.1589101403951645\n",
      "0.19738660752773285\n",
      "0.2588777542114258\n",
      "0.24238218367099762\n",
      "0.27873897552490234\n",
      "0.21942341327667236\n",
      "0.27494773268699646\n",
      "0.1844703108072281\n",
      "0.19678479433059692\n",
      "0.19539648294448853\n",
      "0.2594199478626251\n",
      "0.19101175665855408\n",
      "0.1863790601491928\n",
      "0.18692630529403687\n",
      "0.1644115000963211\n",
      "0.2153693437576294\n",
      "0.18696561455726624\n",
      "0.1836104840040207\n",
      "0.221440389752388\n",
      "0.2005670666694641\n",
      "0.2030390352010727\n",
      "0.167894646525383\n",
      "0.21450185775756836\n",
      "0.25655823945999146\n",
      "0.23137155175209045\n",
      "0.21491718292236328\n",
      "0.19222277402877808\n",
      "0.23380553722381592\n",
      "0.25659340620040894\n",
      "0.18754160404205322\n",
      "0.1727367341518402\n",
      "0.20709703862667084\n",
      "0.17042715847492218\n",
      "0.16619746387004852\n",
      "0.2239956557750702\n",
      "0.22508102655410767\n",
      "0.2200227975845337\n",
      "0.1575751155614853\n",
      "0.18585048615932465\n",
      "0.26708415150642395\n",
      "0.2219141572713852\n",
      "0.15896674990653992\n",
      "0.16502518951892853\n",
      "0.2690296769142151\n",
      "0.15842288732528687\n",
      "0.16074490547180176\n",
      "0.19873513281345367\n",
      "0.2474808394908905\n",
      "0.1794384866952896\n",
      "0.14723172783851624\n",
      "0.11233021318912506\n",
      "0.13811877369880676\n",
      "0.24682559072971344\n",
      "0.24370571970939636\n",
      "0.16057662665843964\n",
      "0.15158019959926605\n",
      "0.24749477207660675\n",
      "0.1908944994211197\n",
      "0.14021684229373932\n",
      "0.14840616285800934\n",
      "0.17943598330020905\n",
      "0.19453859329223633\n",
      "0.2048366814851761\n",
      "0.2217334508895874\n",
      "0.17478665709495544\n",
      "0.1522897630929947\n",
      "0.25138673186302185\n",
      "0.16188016533851624\n",
      "0.18892993032932281\n",
      "0.1832312047481537\n",
      "0.18410183489322662\n",
      "0.21364106237888336\n",
      "0.22001974284648895\n",
      "0.1407351791858673\n",
      "0.15977095067501068\n",
      "0.2325415313243866\n",
      "0.18883733451366425\n",
      "0.2162719964981079\n",
      "0.1422175019979477\n",
      "0.11170122027397156\n",
      "0.16734953224658966\n",
      "0.12400898337364197\n",
      "0.17658238112926483\n",
      "0.1350279152393341\n",
      "0.13114723563194275\n",
      "0.20302458107471466\n",
      "0.130090594291687\n",
      "0.17839229106903076\n",
      "0.1168593317270279\n",
      "0.1519690304994583\n",
      "0.18245288729667664\n",
      "0.17961488664150238\n",
      "0.1126236692070961\n",
      "0.15954940021038055\n",
      "0.1605742871761322\n",
      "0.13247346878051758\n",
      "0.11874326318502426\n",
      "0.20946387946605682\n",
      "0.1395258754491806\n",
      "0.139783576130867\n",
      "0.20825979113578796\n",
      "0.11080038547515869\n",
      "0.22556127607822418\n",
      "0.09054241329431534\n",
      "0.16466744244098663\n",
      "0.1298135668039322\n",
      "0.2210162729024887\n",
      "0.09771018475294113\n",
      "0.09309781342744827\n",
      "0.1972716897726059\n",
      "0.11616428941488266\n",
      "0.18559031188488007\n",
      "0.133042111992836\n",
      "0.12445325404405594\n",
      "0.1785418838262558\n",
      "0.10494956374168396\n",
      "0.1341470628976822\n",
      "0.1274408996105194\n",
      "0.139377161860466\n",
      "0.10860966145992279\n",
      "0.1250748336315155\n",
      "0.15964509546756744\n",
      "0.17278195917606354\n",
      "0.19283097982406616\n",
      "0.10964228212833405\n",
      "0.09119679778814316\n",
      "0.13770441710948944\n",
      "0.13549932837486267\n",
      "0.10347474366426468\n",
      "0.1423066109418869\n",
      "0.14946569502353668\n",
      "0.14597880840301514\n",
      "0.17292052507400513\n",
      "0.1658046990633011\n",
      "0.12023371458053589\n",
      "0.09919639676809311\n",
      "0.11417847871780396\n",
      "0.16671393811702728\n",
      "0.13437919318675995\n",
      "0.1649089753627777\n",
      "0.14141403138637543\n",
      "0.11050211638212204\n",
      "0.14392349123954773\n",
      "0.14681367576122284\n",
      "0.06036539375782013\n",
      "0.13437791168689728\n",
      "0.12632350623607635\n",
      "0.13890179991722107\n",
      "0.12537480890750885\n",
      "0.10663805902004242\n",
      "0.11267074942588806\n",
      "0.07691797614097595\n",
      "0.09299222379922867\n",
      "0.11340715736150742\n",
      "0.10864976048469543\n",
      "0.18754516541957855\n",
      "0.08555586636066437\n",
      "0.14247776567935944\n",
      "0.06539939343929291\n",
      "0.17731225490570068\n",
      "0.16748923063278198\n",
      "0.1361204832792282\n",
      "0.15270228683948517\n",
      "0.10833965241909027\n",
      "0.1341112107038498\n",
      "0.08663898706436157\n",
      "0.13912244141101837\n",
      "0.09544892609119415\n",
      "0.152555912733078\n",
      "0.1056666448712349\n",
      "0.12156254053115845\n",
      "0.1630018949508667\n",
      "0.12542563676834106\n",
      "0.11667951196432114\n",
      "0.12601107358932495\n",
      "0.10961142927408218\n",
      "0.08548755198717117\n",
      "0.10591241717338562\n",
      "0.18422478437423706\n",
      "0.12123408913612366\n",
      "0.08238618820905685\n",
      "0.07731424272060394\n",
      "0.11799917370080948\n",
      "0.11314983665943146\n",
      "0.1081981435418129\n",
      "0.10686902701854706\n",
      "0.1375461220741272\n",
      "0.09629929065704346\n",
      "0.0840371698141098\n",
      "0.14634084701538086\n",
      "0.132319837808609\n",
      "0.14135226607322693\n",
      "0.09046405553817749\n",
      "0.07516913115978241\n",
      "0.14723142981529236\n",
      "0.13118603825569153\n",
      "0.0877591222524643\n",
      "0.0988369882106781\n",
      "0.07498158514499664\n",
      "0.09192933142185211\n",
      "0.09406525641679764\n",
      "0.12142594903707504\n",
      "0.1327049881219864\n",
      "0.09075043350458145\n",
      "0.11150223016738892\n",
      "0.1261557787656784\n",
      "0.1852579414844513\n",
      "0.08311275392770767\n",
      "0.09874127060174942\n",
      "0.10823340713977814\n",
      "0.07408905774354935\n",
      "0.13718213140964508\n",
      "0.12163334339857101\n",
      "0.10184503346681595\n",
      "0.14673615992069244\n",
      "0.095121368765831\n",
      "0.14990632236003876\n",
      "0.12628594040870667\n",
      "0.13020317256450653\n",
      "0.0948481485247612\n",
      "0.1600767821073532\n",
      "0.09031953662633896\n",
      "0.14711883664131165\n",
      "0.10637836158275604\n",
      "0.09529086202383041\n",
      "0.21671219170093536\n",
      "0.06485846638679504\n",
      "0.09768325090408325\n",
      "0.1531873196363449\n",
      "0.08260427415370941\n",
      "0.1592637151479721\n",
      "0.07930003106594086\n",
      "0.07470320165157318\n",
      "0.09156484156847\n",
      "0.09204071760177612\n",
      "0.10159261524677277\n",
      "0.09880833327770233\n",
      "0.0525592565536499\n",
      "0.07771707326173782\n",
      "0.1246384009718895\n",
      "0.08395331352949142\n",
      "0.11046750098466873\n",
      "0.12321186065673828\n",
      "0.0836784839630127\n",
      "0.1062481701374054\n",
      "0.07132379710674286\n",
      "0.19820253551006317\n",
      "0.1358601450920105\n",
      "0.1168643906712532\n",
      "0.1546800583600998\n",
      "0.14358903467655182\n",
      "0.1212603822350502\n",
      "0.08394256234169006\n",
      "0.06526020914316177\n",
      "0.07489166408777237\n",
      "0.11889972537755966\n",
      "0.1145186498761177\n",
      "0.06201513856649399\n",
      "0.10810844600200653\n",
      "0.11860764026641846\n",
      "0.0716552734375\n",
      "0.12825438380241394\n",
      "0.10162419080734253\n",
      "0.1096971184015274\n",
      "0.1341962218284607\n",
      "0.08818275481462479\n",
      "0.06364008784294128\n",
      "0.09286938607692719\n",
      "0.07835742831230164\n",
      "0.07181640714406967\n",
      "0.10900989919900894\n",
      "0.04919523000717163\n",
      "0.07849357277154922\n",
      "0.10308220237493515\n",
      "0.1068297028541565\n",
      "0.10220189392566681\n",
      "0.08431433886289597\n",
      "0.10273419320583344\n",
      "0.10875707864761353\n",
      "0.042887937277555466\n",
      "0.10748463869094849\n",
      "0.11349362134933472\n",
      "0.10258569568395615\n",
      "0.11731698364019394\n",
      "0.10432330518960953\n",
      "0.04683658108115196\n",
      "0.06712965667247772\n",
      "0.16102422773838043\n",
      "0.06094031780958176\n",
      "0.1508016139268875\n",
      "0.12354773283004761\n",
      "0.11912226676940918\n",
      "0.11284526437520981\n",
      "0.15703865885734558\n",
      "0.10978325456380844\n",
      "0.09027139842510223\n",
      "0.11587757617235184\n",
      "0.05256776139140129\n",
      "0.09847988933324814\n",
      "0.07452703267335892\n",
      "0.12970559298992157\n",
      "0.09820663928985596\n",
      "0.10044115036725998\n",
      "0.11257347464561462\n",
      "0.11855572462081909\n",
      "0.052074626088142395\n",
      "0.11482569575309753\n",
      "0.11777273565530777\n",
      "0.09847834706306458\n",
      "0.07671263068914413\n",
      "0.08541377633810043\n",
      "0.08075087517499924\n",
      "0.08305554836988449\n",
      "0.1243610829114914\n",
      "0.05706797540187836\n",
      "0.10385720431804657\n",
      "0.09115216135978699\n",
      "0.110816590487957\n",
      "0.15134809911251068\n",
      "0.09234581142663956\n",
      "0.0316968634724617\n",
      "0.10824482887983322\n",
      "0.07640694826841354\n",
      "0.09011329710483551\n",
      "0.04013682156801224\n",
      "0.0732288658618927\n",
      "0.07970046997070312\n",
      "0.0737009197473526\n",
      "0.1365446001291275\n",
      "0.09656207263469696\n",
      "0.13997188210487366\n",
      "0.09340967983007431\n",
      "0.10255152732133865\n",
      "0.1376510113477707\n",
      "0.10188346356153488\n",
      "0.11763598024845123\n",
      "0.08836621046066284\n",
      "0.08778534829616547\n",
      "0.09260209649801254\n",
      "0.1320282220840454\n",
      "0.08549459278583527\n",
      "0.12454349547624588\n",
      "0.11558341234922409\n",
      "0.09248890727758408\n",
      "0.1531602442264557\n",
      "0.14967328310012817\n",
      "0.048946499824523926\n",
      "0.10145507007837296\n",
      "0.08597984164953232\n",
      "0.09430672228336334\n",
      "0.08999553322792053\n",
      "0.0849057137966156\n",
      "0.07016517966985703\n",
      "0.0805228054523468\n",
      "0.09692487865686417\n",
      "0.11502065509557724\n",
      "0.09265226870775223\n",
      "0.12701193988323212\n",
      "0.07657105475664139\n",
      "0.0770655944943428\n",
      "0.06604830175638199\n",
      "0.09856057167053223\n",
      "0.09157775342464447\n",
      "0.07857944071292877\n",
      "0.08821020275354385\n",
      "0.09219187498092651\n",
      "0.10889828205108643\n",
      "0.09841489791870117\n",
      "0.09271805733442307\n",
      "0.10646743327379227\n",
      "0.07680097967386246\n",
      "0.1337766796350479\n",
      "0.08699503540992737\n",
      "0.06611500680446625\n",
      "0.13241112232208252\n",
      "0.12488006055355072\n",
      "0.10946943610906601\n",
      "0.09490260481834412\n",
      "0.10435207933187485\n",
      "0.09928926825523376\n",
      "0.03901449963450432\n",
      "0.06895419955253601\n",
      "0.10168791562318802\n",
      "0.09930494427680969\n",
      "0.12954363226890564\n",
      "0.08192303776741028\n",
      "0.08724973350763321\n",
      "0.10005372017621994\n",
      "0.09298752248287201\n",
      "0.0567144900560379\n",
      "0.07364367693662643\n",
      "0.09537053108215332\n",
      "0.1314976066350937\n",
      "0.16990387439727783\n",
      "0.059821635484695435\n",
      "0.07953142374753952\n",
      "0.0563548281788826\n",
      "0.11103750765323639\n",
      "0.10603469610214233\n",
      "0.07696680724620819\n",
      "0.07549885660409927\n",
      "0.07423026859760284\n",
      "0.07665583491325378\n",
      "0.058342985808849335\n",
      "0.09504025429487228\n",
      "0.048181094229221344\n",
      "0.05737263336777687\n",
      "0.07519195228815079\n",
      "0.12149111926555634\n",
      "0.06873168051242828\n",
      "0.10213558375835419\n",
      "0.12575559318065643\n",
      "0.13634838163852692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mixstyle_module, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e116b2efbe78469dad1f8db82d695940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9713961482048035     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9713961482048035    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.9713961482048035}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(mixstyle_module, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10e355b1ac55467597ee807c6bda2b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.6532503366470337     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6532503366470337    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.6532503366470337}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(mixstyle_module, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| # Samples | Baseline | MixStyle |\n",
    "| --------- | -------- | -------- |\n",
    "| All       | 0.629    | 0.642    |\n",
    "| 1_000     | 0.569    | 0.576    |\n",
    "| 500       | 0.520    | 0.538    |\n",
    "| 100       | 0.451    | 0.463    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
