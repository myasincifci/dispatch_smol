{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import random\n",
    "import json\n",
    "\n",
    "from data_modules.domainnet_dataset import ImageDataset\n",
    "from data_modules.domainnet_metadata import DOMAIN_NET_DOMAINS, DOMAIN_NET_CLASSES, DOMAIN_NET_DIVISIONS\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "from yasin_utils.image import imagenet_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_map = {}\n",
    "for k, v in DOMAIN_NET_DIVISIONS.items():\n",
    "    for i in v:\n",
    "        division_map[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/data/domainnet_v1.0'\n",
    "# set_map = []\n",
    "# for domain in DOMAIN_NET_DOMAINS:\n",
    "#     try:\n",
    "#         labels = os.listdir(os.path.join(root, domain))\n",
    "#     except:\n",
    "#         raise Exception(f'{domain} directory not found.')\n",
    "#     for label in labels:\n",
    "#         for image in os.listdir(os.path.join(root, domain, label)):\n",
    "#             if label in division_map:\n",
    "#                 set_map.append(\n",
    "#                     dict(\n",
    "#                         img_path=os.path.join(root, domain, label, image),\n",
    "#                         label=division_map[label],\n",
    "#                         domain=domain\n",
    "#                         )\n",
    "#                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random.shuffle(set_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set_map, test_set_map = set_map[:int(0.9*len(set_map))], set_map[int(0.9*len(set_map)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/yasin/repos/dispatch_smol/pretraining/data_modules/train_set_map_domainnet.json') as f:\n",
    "    train_set_map_ = json.load(f)\n",
    "with open('/home/yasin/repos/dispatch_smol/pretraining/data_modules/test_set_map_domainnet.json') as f:\n",
    "    test_set_map_ = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_map = []\n",
    "for sample in train_set_map_:\n",
    "    if sample['label'] in division_map:\n",
    "        new_sample = {**sample}\n",
    "        new_sample['label'] = division_map[sample['label']]\n",
    "        train_set_map.append(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_map = []\n",
    "for sample in test_set_map_:\n",
    "    if sample['label'] in division_map:\n",
    "        new_sample = {**sample}\n",
    "        new_sample['label'] = division_map[sample['label']]\n",
    "        test_set_map.append(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241485, 26659)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set_map), len(test_set_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tool', 'quickdraw'): 12600,\n",
       " ('tool', 'painting'): 4618,\n",
       " ('electricity', 'real'): 10563,\n",
       " ('cloth', 'infograph'): 3370,\n",
       " ('tool', 'real'): 11645,\n",
       " ('mammal', 'quickdraw'): 11309,\n",
       " ('cloth', 'real'): 10397,\n",
       " ('tool', 'clipart'): 3441,\n",
       " ('mammal', 'sketch'): 4644,\n",
       " ('electricity', 'painting'): 2669,\n",
       " ('furniture', 'painting'): 4472,\n",
       " ('cloth', 'painting'): 3192,\n",
       " ('furniture', 'sketch'): 6760,\n",
       " ('building', 'quickdraw'): 9479,\n",
       " ('furniture', 'real'): 15417,\n",
       " ('building', 'real'): 10874,\n",
       " ('mammal', 'clipart'): 3096,\n",
       " ('furniture', 'quickdraw'): 15745,\n",
       " ('mammal', 'infograph'): 3212,\n",
       " ('mammal', 'real'): 13996,\n",
       " ('electricity', 'infograph'): 3744,\n",
       " ('electricity', 'quickdraw'): 11284,\n",
       " ('cloth', 'sketch'): 4374,\n",
       " ('building', 'painting'): 4610,\n",
       " ('mammal', 'painting'): 8114,\n",
       " ('electricity', 'clipart'): 2803,\n",
       " ('cloth', 'clipart'): 3275,\n",
       " ('building', 'sketch'): 4241,\n",
       " ('furniture', 'clipart'): 5199,\n",
       " ('tool', 'sketch'): 4373,\n",
       " ('cloth', 'quickdraw'): 10285,\n",
       " ('building', 'clipart'): 2495,\n",
       " ('building', 'infograph'): 2840,\n",
       " ('furniture', 'infograph'): 5861,\n",
       " ('electricity', 'sketch'): 3683,\n",
       " ('tool', 'infograph'): 2805}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(collections.Counter([(d['label'], d['domain']) for d in train_set_map]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_map = {\n",
    "#     'furniture': {'main_domain': 'clipart', 'target': 5_253},\n",
    "#     'cloth': {'main_domain': 'real', 'target': 10_377},\n",
    "#     'electricity': {'main_domain': 'infograph', 'target': 3_745},\n",
    "#     'building': {'main_domain': 'painting', 'target': 4_570},\n",
    "#     'mammal': {'main_domain': 'quickdraw', 'target': 11_202},\n",
    "#     'tool': {'main_domain': 'sketch', 'target': 4_401},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_map = {\n",
    "    'furniture': {'main_domain': 'clipart', 'target': 100},\n",
    "    'cloth': {'main_domain': 'real', 'target': 100},\n",
    "    'electricity': {'main_domain': 'infograph', 'target': 100},\n",
    "    'building': {'main_domain': 'painting', 'target': 100},\n",
    "    'mammal': {'main_domain': 'quickdraw', 'target': 100},\n",
    "    'tool': {'main_domain': 'sketch', 'target': 100},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_map = {\n",
    "#     'furniture': {'main_domain': 'clipart', 'target': 1_000},\n",
    "#     'cloth': {'main_domain': 'real', 'target': 1_000},\n",
    "#     'electricity': {'main_domain': 'infograph', 'target': 1_000},\n",
    "#     'building': {'main_domain': 'painting', 'target': 1_000},\n",
    "#     'mammal': {'main_domain': 'quickdraw', 'target': 1_000},\n",
    "#     'tool': {'main_domain': 'sketch', 'target': 1_000},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance_map = {\n",
    "#     'furniture': {'main_domain': 'clipart', 'target': 100},\n",
    "#     'cloth': {'main_domain': 'real', 'target': 100},\n",
    "#     'electricity': {'main_domain': 'infograph', 'target': 100},\n",
    "#     'building': {'main_domain': 'painting', 'target': 100},\n",
    "#     'mammal': {'main_domain': 'quickdraw', 'target': 100},\n",
    "#     'tool': {'main_domain': 'sketch', 'target': 100},\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(set_map, balance_map):\n",
    "    pruned_set_map = []\n",
    "    \n",
    "    domains = set([i['domain'] for i in set_map])\n",
    "    counts = {\n",
    "        l: {\n",
    "            d: 0 for d in domains\n",
    "        } for l in balance_map\n",
    "    }\n",
    "    targets = {\n",
    "        l: {\n",
    "            d: balance_map[l]['target'] if d == balance_map[l]['main_domain'] else int(balance_map[l]['target']*0.02) for d in domains\n",
    "        } for l in balance_map\n",
    "    }\n",
    "\n",
    "    for i in set_map:\n",
    "        label, domain = i['label'], i['domain']\n",
    "\n",
    "        if counts[label][domain] < targets[label][domain]:\n",
    "            pruned_set_map.append(i)\n",
    "\n",
    "        counts[label][domain] += 1\n",
    "\n",
    "    return pruned_set_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_map = prune(train_set_map, balance_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tool', 'quickdraw'): 2,\n",
       " ('tool', 'painting'): 2,\n",
       " ('electricity', 'real'): 2,\n",
       " ('cloth', 'infograph'): 2,\n",
       " ('tool', 'real'): 2,\n",
       " ('mammal', 'quickdraw'): 100,\n",
       " ('cloth', 'real'): 100,\n",
       " ('tool', 'clipart'): 2,\n",
       " ('mammal', 'sketch'): 2,\n",
       " ('electricity', 'painting'): 2,\n",
       " ('furniture', 'painting'): 2,\n",
       " ('cloth', 'painting'): 2,\n",
       " ('furniture', 'sketch'): 2,\n",
       " ('building', 'quickdraw'): 2,\n",
       " ('furniture', 'real'): 2,\n",
       " ('building', 'real'): 2,\n",
       " ('mammal', 'clipart'): 2,\n",
       " ('furniture', 'quickdraw'): 2,\n",
       " ('mammal', 'infograph'): 2,\n",
       " ('mammal', 'real'): 2,\n",
       " ('electricity', 'infograph'): 100,\n",
       " ('electricity', 'quickdraw'): 2,\n",
       " ('cloth', 'sketch'): 2,\n",
       " ('building', 'painting'): 100,\n",
       " ('mammal', 'painting'): 2,\n",
       " ('electricity', 'clipart'): 2,\n",
       " ('cloth', 'clipart'): 2,\n",
       " ('building', 'sketch'): 2,\n",
       " ('furniture', 'clipart'): 100,\n",
       " ('tool', 'sketch'): 100,\n",
       " ('cloth', 'quickdraw'): 2,\n",
       " ('building', 'clipart'): 2,\n",
       " ('building', 'infograph'): 2,\n",
       " ('furniture', 'infograph'): 2,\n",
       " ('electricity', 'sketch'): 2,\n",
       " ('tool', 'infograph'): 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(collections.Counter([(d['label'], d['domain']) for d in train_set_map]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnbalancedDomainNetDataset(ImageDataset):\n",
    "    def __init__(self, set_map, transform=None) -> None:\n",
    "\n",
    "        super().__init__(set_map, transform)\n",
    "        self.class_map = {\n",
    "            'furniture': 0,\n",
    "            'cloth': 1,\n",
    "            'electricity': 2,\n",
    "            'building': 3,\n",
    "            'mammal': 4,\n",
    "            'tool': 5,\n",
    "        }\n",
    "        self.domain_map = {\n",
    "            'clipart': 0,\n",
    "            'real': 1,\n",
    "            'infograph': 2,\n",
    "            'painting': 3,\n",
    "            'quickdraw': 4,\n",
    "            'sketch': 5,\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = super().__getitem__(index)\n",
    "        item['label'] = self.class_map[item['label']]\n",
    "        item['domain'] = self.domain_map[item['domain']]\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_transform = T.Compose([\n",
    "    # T.RandomResizedCrop(128),\n",
    "    # T.RandomHorizontalFlip(),\n",
    "    T.Resize((128,128)),\n",
    "    T.ToTensor(),\n",
    "    imagenet_normalize,\n",
    "])\n",
    "val_transform = T.Compose([\n",
    "    # T.Resize(156),\n",
    "    # T.CenterCrop(128),\n",
    "    T.Resize((128,128)),\n",
    "    T.ToTensor(),\n",
    "    imagenet_normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = UnbalancedDomainNetDataset(set_map=train_set_map, transform=train_transform)\n",
    "test_set = UnbalancedDomainNetDataset(set_map=test_set_map, transform=val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=8, pin_memory=True, persistent_workers=True, drop_last=True)\n",
    "val_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=8, pin_memory=True, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 26659)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set), len(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models.resnet import resnet50\n",
    "import pytorch_lightning as L\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProbe(L.LightningModule):\n",
    "    def __init__(self, backbone, emb_dim, num_classes, lr=1e-3) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone: nn.Module = backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.backbone.eval()\n",
    "\n",
    "        self.linear_head: nn.Module = nn.Linear(emb_dim, num_classes)\n",
    "        # self.linear_head: nn.Module = nn.Sequential(\n",
    "        #     nn.Linear(emb_dim, 1024),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(1024, 512),\n",
    "        #     nn.Linear(512, num_classes)\n",
    "        # ) \n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.test_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.linear_head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, bacth_idx):\n",
    "        X = batch['image']\n",
    "        t = batch['label']\n",
    "\n",
    "        y = self.forward(X)\n",
    "        loss = self.criterion(y, t)\n",
    "\n",
    "        print(loss.item())\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X = batch['image']\n",
    "        t = batch['label']\n",
    "\n",
    "        y = self.forward(X)\n",
    "        acc = self.test_accuracy(y, t)\n",
    "\n",
    "        self.log('accuracy', acc, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.linear_head.parameters(), lr=self.lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 20)\n",
    "\n",
    "        return [optimizer], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_from_ckpt(ckpt_path: str) -> torch.nn.Module:\n",
    "    state_dict = torch.load(ckpt_path)[\"state_dict\"]\n",
    "    state_dict = OrderedDict([\n",
    "        (\".\".join(name.split(\".\")[1:]), param) for name, param in state_dict.items() if name.startswith(\"backbone\")\n",
    "    ])\n",
    "\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "model_bl  = resnet50()\n",
    "weights_bl = get_backbone_from_ckpt(\"/home/yasin/Downloads/final_baseline.ckpt\")\n",
    "model_bl.load_state_dict(weights_bl, strict=False)\n",
    "model_bl.fc = torch.nn.Identity()\n",
    "model_bl = model_bl.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MixStyle Model\n",
    "model_ms  = resnet50()\n",
    "weights_ms = get_backbone_from_ckpt(\"/home/yasin/Downloads/final_mixstyle.ckpt\")\n",
    "model_ms.load_state_dict(weights_ms, strict=False)\n",
    "model_ms.fc = torch.nn.Identity()\n",
    "model_ms = model_ms.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_module = LinearProbe(model_bl, emb_dim=2048, num_classes=6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixstyle_module = LinearProbe(model_ms, emb_dim=2048, num_classes=6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | backbone      | ResNet             | 23.5 M\n",
      "1 | linear_head   | Linear             | 12.3 K\n",
      "2 | criterion     | CrossEntropyLoss   | 0     \n",
      "3 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d7818bee5e482d96f4d4296d52e0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.848394751548767\n",
      "1.6978671550750732\n",
      "1.5292961597442627\n",
      "1.4333938360214233\n",
      "1.2815630435943604\n",
      "1.1749796867370605\n",
      "1.0765836238861084\n",
      "0.9487751722335815\n",
      "0.8977640867233276\n",
      "0.8391698598861694\n",
      "0.7664602994918823\n",
      "0.738565981388092\n",
      "0.6487065553665161\n",
      "0.6659150719642639\n",
      "0.6047763228416443\n",
      "0.6039161682128906\n",
      "0.502172589302063\n",
      "0.5991513133049011\n",
      "0.575089693069458\n",
      "0.48921364545822144\n",
      "0.53260737657547\n",
      "0.48354169726371765\n",
      "0.474668025970459\n",
      "0.46403902769088745\n",
      "0.5051780939102173\n",
      "0.4321802258491516\n",
      "0.4562263488769531\n",
      "0.44223126769065857\n",
      "0.4226888120174408\n",
      "0.4479796588420868\n",
      "0.4155516028404236\n",
      "0.4232303500175476\n",
      "0.45911839604377747\n",
      "0.42386698722839355\n",
      "0.41045141220092773\n",
      "0.4452684819698334\n",
      "0.41823261976242065\n",
      "0.4454236328601837\n",
      "0.36650848388671875\n",
      "0.4826802611351013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(baseline_module, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dad025a160e4638a5aa6c4f53dc800b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.88671875         </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.88671875        \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.88671875}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(baseline_module, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f21a71aa574a318d8f473154239d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 35. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2997486889362335     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2997486889362335    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.2997486889362335}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(baseline_module, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | backbone      | ResNet             | 23.5 M\n",
      "1 | linear_head   | Linear             | 12.3 K\n",
      "2 | criterion     | CrossEntropyLoss   | 0     \n",
      "3 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "12.3 K    Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.081    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1481cfe0024e63931e9b219247c4c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8548887968063354\n",
      "1.7114722728729248\n",
      "1.5360091924667358\n",
      "1.4342327117919922\n",
      "1.304953932762146\n",
      "1.1808087825775146\n",
      "1.1333686113357544\n",
      "0.982710599899292\n",
      "0.9016388058662415\n",
      "0.8918410539627075\n",
      "0.8006599545478821\n",
      "0.7706559896469116\n",
      "0.6919435262680054\n",
      "0.6780275702476501\n",
      "0.6313337683677673\n",
      "0.6375774145126343\n",
      "0.6314430236816406\n",
      "0.6137170791625977\n",
      "0.5670182704925537\n",
      "0.5655918717384338\n",
      "0.5592472553253174\n",
      "0.5304793119430542\n",
      "0.5131610631942749\n",
      "0.5166656970977783\n",
      "0.5268531441688538\n",
      "0.47509777545928955\n",
      "0.42184948921203613\n",
      "0.5753235816955566\n",
      "0.4534452557563782\n",
      "0.5093572735786438\n",
      "0.4301510751247406\n",
      "0.5087066292762756\n",
      "0.487271249294281\n",
      "0.46189698576927185\n",
      "0.4839189648628235\n",
      "0.475533127784729\n",
      "0.447551965713501\n",
      "0.46548572182655334\n",
      "0.41900771856307983\n",
      "0.46061593294143677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mixstyle_module, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b45772b9cbf450ab8873de4baf7ec33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">        0.88671875         </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m       0.88671875        \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.88671875}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(mixstyle_module, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c161b96400404231b466ee872d917120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.3087887763977051     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.3087887763977051    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.3087887763977051}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(mixstyle_module, dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| # Samples | Baseline | MixStyle |\n",
    "| --------- | -------- | -------- |\n",
    "| All       | 0.629    | 0.642    |\n",
    "| 1_000     | 0.569    | 0.576    |\n",
    "| 500       | 0.520    | 0.538    |\n",
    "| 100       | 0.451    | 0.463    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
