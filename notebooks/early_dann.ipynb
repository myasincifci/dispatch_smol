{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Function\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.resnet import resnet50, ResNet50_Weights\n",
    "\n",
    "import pytorch_lightning as L\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "from wilds import get_dataset\n",
    "from wilds.common.data_loaders import get_eval_loader, get_train_loader\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "\n",
    "from utils import get_backbone_from_ckpt, DomainMapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseLayerF(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output = grad_output.neg() * ctx.alpha\n",
    "\n",
    "        return output, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyDANN(nn.Module):\n",
    "    def __init__(self, weights, alpha=0.15) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = self._make_backbone(weights)\n",
    "        self.disc_head = nn.Linear(64+256+512+1024+2048, 3)\n",
    "\n",
    "        self.crit_pred = nn.CrossEntropyLoss()\n",
    "        self.crit_disc = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        z0 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "\n",
    "        z1 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.layer2(x)\n",
    "        \n",
    "        z2 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.layer3(x)\n",
    "        \n",
    "        z3 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        z4 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "\n",
    "        f = torch.flatten(x, 1)\n",
    "\n",
    "        z_ = torch.cat([z0, z1, z2, z3, z4], dim=1)\n",
    "        z_ = ReverseLayerF.apply(z_, self.alpha)\n",
    "\n",
    "        y = self.backbone.fc(f)\n",
    "        z = self.disc_head(z_)\n",
    "\n",
    "        return y, z\n",
    "    \n",
    "    def embed(self, x: torch.Tensor):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        z0 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        z1 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.layer2(x)\n",
    "        z2 = x.mean(dim=[2,3])\n",
    "        \n",
    "        x = self.backbone.layer3(x)\n",
    "        z3 = x.mean(dim=[2,3])\n",
    "        \n",
    "        x = self.backbone.layer4(x)\n",
    "        z4 = x.mean(dim=[2,3])\n",
    "\n",
    "        x = self.backbone.avgpool(x).squeeze()\n",
    "    \n",
    "        return {\n",
    "            \"z0\": z0,\n",
    "            \"z1\": z1,\n",
    "            \"z2\": z2,\n",
    "            \"z3\": z3,\n",
    "            \"z4\": z4,\n",
    "            \"x\": x\n",
    "        }\n",
    "    \n",
    "    def _make_backbone(self, weights):\n",
    "        if weights == \"scratch\":\n",
    "            backbone = resnet50(num_classes=2)\n",
    "        elif weights == \"ImageNet\":\n",
    "            backbone = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "            backbone.fc = nn.Linear(2048, 2)\n",
    "        else:\n",
    "            backbone = resnet50(num_classes=2)\n",
    "            missing_keys, unexpected_keys = backbone.load_state_dict(get_backbone_from_ckpt(weights), strict=False)\n",
    "            print(\"missing:\", missing_keys, \"unexpected:\", unexpected_keys)\n",
    "\n",
    "        return backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(L.LightningModule):\n",
    "    def __init__(self, grouper: CombinatorialGrouper, dom_mapper: DomainMapper, in_channels=3, num_cls=2, pretrain=None, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "        # self.model = CNN(in_channels=in_channels, num_classes=num_cls)\n",
    "        self.model = EarlyDANN(weights='scratch')\n",
    "\n",
    "        self.criterion = torch.nn.CrossEntropyLoss()\n",
    "        self.optimizer = torch.optim.SGD(params=self.parameters(), lr=1e-3, weight_decay=1e-2, momentum=0.9)\n",
    "        self.metric = Accuracy(num_classes=2, task='multiclass')\n",
    "\n",
    "        self.grouper: CombinatorialGrouper = grouper\n",
    "        self.dom_mapper: DomainMapper = dom_mapper\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, t, M = batch\n",
    "        d = self.grouper.metadata_to_group(M.cpu())\n",
    "        d = self.dom_mapper(d).cuda()\n",
    "\n",
    "        y, z = self.model(X)\n",
    "        \n",
    "        loss_y = self.criterion(y, t)\n",
    "        loss_d = self.criterion(z, d)\n",
    "\n",
    "        self.log(\"loss_y\", loss_y)\n",
    "        self.log(\"loss_d\", loss_d)\n",
    "\n",
    "        return loss_y + loss_d\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, t, _ = batch\n",
    "\n",
    "        y = self.model(X).argmax(dim=1)\n",
    "        \n",
    "        accuracy = self.metric(y, t)\n",
    "\n",
    "        self.log('accuracy', accuracy)\n",
    "\n",
    "        return accuracy\n",
    "    \n",
    "    def configure_optimizers(self) -> Any:\n",
    "        return self.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = get_dataset(\"camelyon17\", root_dir=\"../../data/\")\n",
    "train_set = dataset.get_subset(\"train\", transform=transform)\n",
    "val_set = dataset.get_subset(\"id_val\", transform=transform)\n",
    "test_set = dataset.get_subset('test', transform=transform)\n",
    "\n",
    "grouper = CombinatorialGrouper(dataset, ['hospital'])\n",
    "dom_mapper = DomainMapper(train_set.metadata_array[:,0])\n",
    "\n",
    "train_loader = get_train_loader(\"standard\", train_set, grouper=grouper,uniform_over_groups=True, batch_size=32, num_workers=8)\n",
    "val_loader = get_eval_loader('standard', val_set, batch_size=64, num_workers=8)\n",
    "test_loader = get_eval_loader('standard', test_set, batch_size=64, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    accelerator=\"auto\", \n",
    "    max_epochs=10, \n",
    "    # val_check_interval=int(len(train_loader)/3)\n",
    ")\n",
    "\n",
    "model = SimpleCNN(grouper=grouper, dom_mapper=dom_mapper, in_channels=3, num_cls=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/configuration_validator.py:71: PossibleUserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | EarlyDANN          | 23.5 M\n",
      "1 | criterion | CrossEntropyLoss   | 0     \n",
      "2 | metric    | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.095    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73f590ce9b0421894be8843de7d8dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=train_loader,\n",
    "    # val_dataloaders=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model_ = model.model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "grouper = CombinatorialGrouper(dataset, ['hospital'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "source_set = dataset.get_subset(\"train\", transform=transform, frac=10_000/len(train_set))\n",
    "target_set = dataset.get_subset(\"test\", transform=transform, frac=10_000/len(test_set))\n",
    "\n",
    "source_loader = get_eval_loader(\"standard\", source_set, batch_size=BS, num_workers=8, grouper=grouper)\n",
    "target_loader = get_eval_loader(\"standard\", target_set, batch_size=BS, num_workers=8, grouper=grouper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import umap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def plot_layer(ax, source: torch.Tensor, target: torch.Tensor, layer='x', acc: float=0.0):\n",
    "    reducer = umap.UMAP(n_neighbors=5, n_epochs=1000, min_dist=0.1)\n",
    "    all_embeddings = torch.cat([source[layer], target[layer]],dim=0)\n",
    "    all_targets = torch.cat([source['t'], target['t']], dim=0)\n",
    "    \n",
    "    X_scaled = StandardScaler().fit_transform(all_embeddings)\n",
    "\n",
    "    reducer = umap.UMAP(n_neighbors=5, min_dist=0.07)\n",
    "    X_reduced = reducer.fit_transform(X_scaled)\n",
    "\n",
    "    source_target = torch.cat([torch.zeros(10_000), torch.ones(10_000)])\n",
    "\n",
    "    color_values = torch.cat([source_target[None,:], all_targets[None,:]], dim=0)\n",
    "\n",
    "    color_map = {\n",
    "        (0,0): \"royalblue\", # source, no_tumor\n",
    "        (0,1): \"mediumaquamarine\", # source, tumor\n",
    "        (1,0): \"gold\", # target, no_tumor\n",
    "        (1,1): \"goldenrod\" # target, tumor\n",
    "    }\n",
    "\n",
    "    colors_master = [color_map[tuple(x.to(int).tolist())] for x in color_values.T]\n",
    "\n",
    "    ax.scatter(\n",
    "        X_reduced[:, 0],\n",
    "        X_reduced[:, 1],\n",
    "        c=colors_master,\n",
    "        s=0.05\n",
    "    )\n",
    "    ax.set_xlabel(f\"Layer: {layer}\\n Accuracy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def predict_domain(source, target, layer='x'):\n",
    "    X = torch.cat([source[layer], target[layer]], dim=0)\n",
    "    t = torch.cat([source['d'], target['d']], dim=0)\n",
    "\n",
    "    X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2, random_state=42)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()), \n",
    "        ('lor', LogisticRegression(max_iter=400, C=0.01))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, t_train)\n",
    "    # print(classification_report(t_test, pipe.predict(X_test)))\n",
    "\n",
    "    return accuracy_score(t_test, pipe.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def compute_embeddings(model: nn.Module, source_loader, target_loader):\n",
    "    num_samples_source = source_loader.dataset.__len__()\n",
    "    num_samples_target = target_loader.dataset.__len__()\n",
    "\n",
    "    source = {\n",
    "        'z0': torch.empty((num_samples_source, 64)),\n",
    "        'z1': torch.empty((num_samples_source, 256)),\n",
    "        'z2': torch.empty((num_samples_source, 512)),\n",
    "        'z3': torch.empty((num_samples_source, 1024)),\n",
    "        'z4': torch.empty((num_samples_source, 2048)),\n",
    "        'x': torch.empty((num_samples_source, 2048)),\n",
    "        't': torch.empty((num_samples_source)),\n",
    "        'd': torch.empty((num_samples_source)),\n",
    "    }\n",
    "    target = {\n",
    "        'z0': torch.empty((num_samples_target, 64)),\n",
    "        'z1': torch.empty((num_samples_target, 256)),\n",
    "        'z2': torch.empty((num_samples_target, 512)),\n",
    "        'z3': torch.empty((num_samples_target, 1024)),\n",
    "        'z4': torch.empty((num_samples_target, 2048)),\n",
    "        'x': torch.empty((num_samples_target, 2048)),\n",
    "        't': torch.empty((num_samples_target)),\n",
    "        'd': torch.empty((num_samples_target)),\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, t, M) in enumerate(tqdm(source_loader)):\n",
    "            bs = len(X)\n",
    "\n",
    "            d = grouper.metadata_to_group(M)\n",
    "\n",
    "            embs = model.embed(X.cuda())\n",
    "            source['z0'][i*BS:i*BS+bs] = embs['z0'].cpu()\n",
    "            source['z1'][i*BS:i*BS+bs] = embs['z1'].cpu()\n",
    "            source['z2'][i*BS:i*BS+bs] = embs['z2'].cpu()\n",
    "            source['z3'][i*BS:i*BS+bs] = embs['z3'].cpu()\n",
    "            source['z4'][i*BS:i*BS+bs] = embs['z4'].cpu()\n",
    "            source['x'][i*BS:i*BS+bs] = embs['x'].cpu()\n",
    "            source['t'][i*BS:i*BS+bs] = t\n",
    "            source['d'][i*BS:i*BS+bs] = d\n",
    "\n",
    "        for i, (X, t, M) in enumerate(tqdm(target_loader)):\n",
    "            bs = len(X)\n",
    "\n",
    "            d = grouper.metadata_to_group(M)\n",
    "\n",
    "            embs = model.embed(X.cuda())\n",
    "            target['z0'][i*BS:i*BS+bs] = embs['z0'].cpu()\n",
    "            target['z1'][i*BS:i*BS+bs] = embs['z1'].cpu()\n",
    "            target['z2'][i*BS:i*BS+bs] = embs['z2'].cpu()\n",
    "            target['z3'][i*BS:i*BS+bs] = embs['z3'].cpu()\n",
    "            target['z4'][i*BS:i*BS+bs] = embs['z4'].cpu()\n",
    "            target['x'][i*BS:i*BS+bs] = embs['x'].cpu()\n",
    "            target['t'][i*BS:i*BS+bs] = t\n",
    "            target['d'][i*BS:i*BS+bs] = d\n",
    "\n",
    "    return source, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def evaluate(model: nn.Module, source_loader, target_loader):\n",
    "    source, target = compute_embeddings(model, source_loader, target_loader)\n",
    "\n",
    "    # Compute domain accuracy\n",
    "    acc_l0 = predict_domain(source, target, 'z0')\n",
    "    acc_l1 = predict_domain(source, target, 'z1')\n",
    "    acc_l2 = predict_domain(source, target, 'z2')\n",
    "    acc_l3 = predict_domain(source, target, 'z3')\n",
    "    acc_l4 = predict_domain(source, target, 'z4')\n",
    "\n",
    "    # Plot embeddings\n",
    "    fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(1,5)\n",
    "\n",
    "    fig.set_figheight(3)\n",
    "    fig.set_figwidth(18)\n",
    "\n",
    "    plot_layer(ax0, source, target, layer='z0', acc=acc_l0)\n",
    "    plot_layer(ax1, source, target, layer='z1', acc=acc_l1)\n",
    "    plot_layer(ax2, source, target, layer='z2', acc=acc_l2)\n",
    "    plot_layer(ax3, source, target, layer='z3', acc=acc_l3)\n",
    "    plot_layer(ax4, source, target, layer='z4', acc=acc_l4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mOSError: [Errno 28] No space left on device. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "evaluate(model_, source_loader, target_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
