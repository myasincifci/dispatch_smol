{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, OrderedDict, List, Dict\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models.resnet import resnet50\n",
    "from torchvision.transforms import v2 as T\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from torchmetrics import Accuracy\n",
    "from lightly.transforms.utils import IMAGENET_NORMALIZE\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, set_map: List[Dict], transform=None) -> None:\n",
    "        ''' Each item in set_map is expected to contain:\n",
    "                img_path: Full path to image,\n",
    "                label: Label corresponding to image at img_path\n",
    "        '''\n",
    "\n",
    "        self.set_map = set_map\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.set_map)\n",
    "    \n",
    "    def __getitem__(self, index):   \n",
    "        sample = self.set_map[index]\n",
    "\n",
    "        # image = read_image(sample['img_path'])\n",
    "        image = Image.open(sample['img_path'])\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return dict(image=image, **sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train_unbalanced_small.json', 'r') as file:\n",
    "    train_set_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test_unbalanced.json', 'r') as file:\n",
    "    test_set_map = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'DG': 0,\n",
    "    'PH': 1,\n",
    "    'EH': 2,\n",
    "    'G': 3\n",
    "}\n",
    "\n",
    "domain_map = {\n",
    "    'cartoon': 0,\n",
    "    'art_painting': 1,\n",
    "    'photo': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in train_set_map:\n",
    "    elem['label'] = label_map[elem['label']]\n",
    "for elem in test_set_map:\n",
    "    elem['label'] = label_map[elem['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([\n",
    "    T.Resize(96),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=IMAGENET_NORMALIZE[\"mean\"],\n",
    "        std=IMAGENET_NORMALIZE[\"std\"],\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ImageDataset(train_set_map, transform=transform)\n",
    "test_set = ImageDataset(test_set_map, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=256, shuffle=True, num_workers=4, persistent_workers=True, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=256, shuffle=False, num_workers=4, persistent_workers=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for elem in train_set_map:\n",
    "    domain = elem['domain']\n",
    "    label = elem['label']\n",
    "\n",
    "    if domain not in stats.keys() :\n",
    "        stats[domain] = {}\n",
    "\n",
    "    if label not in stats[domain].keys():\n",
    "        stats[domain][label] = 1\n",
    "    else:\n",
    "        stats[domain][label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sketch': {3: 100, 1: 10, 2: 10, 0: 10},\n",
       " 'cartoon': {2: 100, 3: 10, 0: 10, 1: 10},\n",
       " 'photo': {1: 100, 2: 10, 3: 10, 0: 10},\n",
       " 'art_painting': {0: 100, 3: 10, 2: 10, 1: 10}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {}\n",
    "for elem in test_set_map:\n",
    "    domain = elem['domain']\n",
    "    label = elem['label']\n",
    "\n",
    "    if domain not in stats.keys() :\n",
    "        stats[domain] = {}\n",
    "\n",
    "    if label not in stats[domain].keys():\n",
    "        stats[domain][label] = 1\n",
    "    else:\n",
    "        stats[domain][label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'art_painting': {1: 74, 2: 48, 0: 79, 3: 16},\n",
       " 'sketch': {0: 144, 3: 58, 2: 145, 1: 19},\n",
       " 'photo': {2: 37, 1: 65, 0: 47, 3: 19},\n",
       " 'cartoon': {0: 83, 2: 78, 3: 12, 1: 76}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class LinearProbe(L.LightningModule):\n",
    "    def __init__(self, backbone, emb_dim, num_classes, lr=1e-2) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone: nn.Module = backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.linear_head: nn.Module = nn.Linear(emb_dim, num_classes)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "\n",
    "        self.test_accuracy = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.linear_head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, bacth_idx):\n",
    "        X = batch['image']\n",
    "        t = batch['label']\n",
    "\n",
    "        y = self.forward(X)\n",
    "        loss = self.criterion(y, t)\n",
    "\n",
    "        print(loss.item())\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        X = batch['image']\n",
    "        t = batch['label']\n",
    "\n",
    "        y = self.forward(X)\n",
    "        acc = self.test_accuracy(y, t)\n",
    "\n",
    "        self.log('accuracy', acc, on_epoch=True)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.linear_head.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_backbone_from_ckpt(ckpt_path: str) -> torch.nn.Module:\n",
    "    state_dict = torch.load(ckpt_path)[\"state_dict\"]\n",
    "    state_dict = OrderedDict([\n",
    "        (\".\".join(name.split(\".\")[1:]), param) for name, param in state_dict.items() if name.startswith(\"backbone\")\n",
    "    ])\n",
    "\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Model\n",
    "model_bl  = resnet50()\n",
    "weights_bl = get_backbone_from_ckpt(\"./data/r50_bl.ckpt\")\n",
    "model_bl.load_state_dict(weights_bl, strict=False)\n",
    "model_bl.fc = torch.nn.Identity()\n",
    "model_bl = model_bl.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MixStyle Model\n",
    "model_ms  = resnet50()\n",
    "weights_ms = get_backbone_from_ckpt(\"./data/r50_ms.ckpt\")\n",
    "model_ms.load_state_dict(weights_ms, strict=False)\n",
    "model_ms.fc = torch.nn.Identity()\n",
    "model_ms = model_ms.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_module = LinearProbe(model_bl, emb_dim=2048, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixstyle_module = LinearProbe(model_ms, emb_dim=2048, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | backbone      | ResNet             | 23.5 M\n",
      "1 | linear_head   | Linear             | 8.2 K \n",
      "2 | criterion     | CrossEntropyLoss   | 0     \n",
      "3 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "8.2 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.065    Total estimated model params size (MB)\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a45c9cf44a46d590f75fa14fc95db4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.477798342704773\n",
      "0.4086325764656067\n",
      "0.9733635783195496\n",
      "0.07623127102851868\n",
      "0.10411446541547775\n",
      "0.5635597705841064\n",
      "0.0510961078107357\n",
      "0.06843748688697815\n",
      "0.17344966530799866\n",
      "0.06195175647735596\n",
      "0.015191998332738876\n",
      "0.13128197193145752\n",
      "0.028455037623643875\n",
      "0.02887888252735138\n",
      "0.009589600376784801\n",
      "0.019996289163827896\n",
      "0.02381395921111107\n",
      "1.0483425855636597\n",
      "0.021778400987386703\n",
      "0.019823292270302773\n",
      "0.013069654814898968\n",
      "0.016400428488850594\n",
      "0.03993683680891991\n",
      "0.6663119196891785\n",
      "0.022871023043990135\n",
      "0.014130493625998497\n",
      "0.6679455041885376\n",
      "0.00603184150531888\n",
      "0.01968163065612316\n",
      "0.4299355149269104\n",
      "0.028557414188981056\n",
      "0.00897170975804329\n",
      "0.37961119413375854\n",
      "0.03277336806058884\n",
      "0.013349609449505806\n",
      "1.2020924091339111\n",
      "0.014676308259367943\n",
      "0.035111356526613235\n",
      "0.1739080548286438\n",
      "0.019004536792635918\n",
      "0.02314092218875885\n",
      "0.06399066746234894\n",
      "0.008587773889303207\n",
      "0.01907062530517578\n",
      "0.20455452799797058\n",
      "0.012444416992366314\n",
      "0.009273559786379337\n",
      "0.011083994060754776\n",
      "0.014807040803134441\n",
      "0.028192071244120598\n",
      "0.38400208950042725\n",
      "0.0366787426173687\n",
      "0.016110191121697426\n",
      "0.5491304993629456\n",
      "0.04297906160354614\n",
      "0.012738182209432125\n",
      "0.031310029327869415\n",
      "0.059013187885284424\n",
      "0.010062926448881626\n",
      "0.002589023672044277\n",
      "0.043839793652296066\n",
      "0.02128690481185913\n",
      "0.005115211941301823\n",
      "0.0064408984035253525\n",
      "0.04217972606420517\n",
      "0.9167510271072388\n",
      "0.01361764408648014\n",
      "0.03615545108914375\n",
      "0.28017348051071167\n",
      "0.023873362690210342\n",
      "0.009738246910274029\n",
      "0.0002720848424360156\n",
      "0.020769570022821426\n",
      "0.01176157221198082\n",
      "0.18593469262123108\n",
      "0.01788223721086979\n",
      "0.027774488553404808\n",
      "0.506773829460144\n",
      "0.01427827775478363\n",
      "0.015755604952573776\n",
      "0.23773688077926636\n",
      "0.016561750322580338\n",
      "0.01369963027536869\n",
      "0.0025631533935666084\n",
      "0.020335232838988304\n",
      "0.02614840678870678\n",
      "0.0012066802009940147\n",
      "0.050081849098205566\n",
      "0.011703258380293846\n",
      "0.06514010578393936\n",
      "0.010516886599361897\n",
      "0.02511167712509632\n",
      "0.04693296551704407\n",
      "0.005630052648484707\n",
      "0.01952417381107807\n",
      "0.0004504722310230136\n",
      "0.003814487252384424\n",
      "0.009498484432697296\n",
      "0.026822973042726517\n",
      "0.004060530103743076\n",
      "0.007126773241907358\n",
      "0.026999905705451965\n",
      "0.003776875324547291\n",
      "0.0025244932621717453\n",
      "0.14275431632995605\n",
      "0.005474470555782318\n",
      "0.006744137033820152\n",
      "0.27577465772628784\n",
      "0.0061887409538030624\n",
      "0.0013737584231421351\n",
      "0.4683798849582672\n",
      "0.0014683736953884363\n",
      "0.006886317394673824\n",
      "0.25807860493659973\n",
      "0.0033694421872496605\n",
      "0.002857307903468609\n",
      "0.2722069323062897\n",
      "0.010300182737410069\n",
      "0.002430508378893137\n",
      "0.009198362939059734\n",
      "0.002194543369114399\n",
      "0.014288835227489471\n",
      "0.21443423628807068\n",
      "0.0022839438170194626\n",
      "0.048004280775785446\n",
      "2.076582670211792\n",
      "0.019615869969129562\n",
      "0.01596684753894806\n",
      "0.04080428555607796\n",
      "0.0009541611652821302\n",
      "0.05150693282485008\n",
      "1.4153988361358643\n",
      "0.017045071348547935\n",
      "0.004475920926779509\n",
      "0.058675989508628845\n",
      "0.01145980041474104\n",
      "0.006006100680679083\n",
      "0.17057566344738007\n",
      "0.03803035989403725\n",
      "0.017153050750494003\n",
      "0.011645831167697906\n",
      "0.04034050926566124\n",
      "0.015106240287423134\n",
      "0.42649438977241516\n",
      "0.015589788556098938\n",
      "0.05076645687222481\n",
      "0.03511442989110947\n",
      "0.028575873002409935\n",
      "0.04177630692720413\n",
      "0.019103948026895523\n",
      "0.017901120707392693\n",
      "0.014292120933532715\n",
      "0.29202133417129517\n",
      "0.0035825821105390787\n",
      "0.015963248908519745\n",
      "0.17252947390079498\n",
      "0.00325216306373477\n",
      "0.015368396416306496\n",
      "0.23094239830970764\n",
      "0.006059455219656229\n",
      "0.033343687653541565\n",
      "0.311991423368454\n",
      "0.006114337593317032\n",
      "0.02422843687236309\n",
      "0.35133346915245056\n",
      "0.023515773937106133\n",
      "0.00026299877208657563\n",
      "0.00036365672713145614\n",
      "0.050436507910490036\n",
      "0.012860016897320747\n",
      "0.6066374182701111\n",
      "0.030697248876094818\n",
      "0.0348501056432724\n",
      "0.5799733400344849\n",
      "0.04694414138793945\n",
      "0.0024849711917340755\n",
      "0.03166327252984047\n",
      "0.01622810773551464\n",
      "0.0009295223280787468\n",
      "0.029771506786346436\n",
      "0.009089559316635132\n",
      "0.020654426887631416\n",
      "0.007218979764729738\n",
      "0.019787950441241264\n",
      "0.006251801736652851\n",
      "0.0010741116711869836\n",
      "0.030855195596814156\n",
      "0.010719389654695988\n",
      "0.710732638835907\n",
      "0.0060532791540026665\n",
      "0.026344135403633118\n",
      "0.6126811504364014\n",
      "0.021651193499565125\n",
      "0.008138859644532204\n",
      "0.44601303339004517\n",
      "0.03172918036580086\n",
      "0.006832548417150974\n",
      "0.18623459339141846\n",
      "0.01836945116519928\n",
      "0.019613994285464287\n",
      "4.073472518939525e-05\n",
      "0.04659450799226761\n",
      "0.0003639801871031523\n",
      "0.010554485023021698\n",
      "0.005121658090502024\n",
      "0.030048208311200142\n",
      "0.0892220288515091\n",
      "0.005407839082181454\n",
      "0.008091852068901062\n",
      "0.8304099440574646\n",
      "0.0048598614521324635\n",
      "0.003246114356443286\n",
      "0.0019089510897174478\n",
      "0.0028897582087665796\n",
      "0.0020448381546884775\n",
      "0.08420354872941971\n",
      "0.00012018893175991252\n",
      "0.006168255116790533\n",
      "1.1063158512115479\n",
      "0.02055959776043892\n",
      "0.009427672252058983\n",
      "0.593353271484375\n",
      "0.005508329253643751\n",
      "0.0014460115926340222\n",
      "0.9350112080574036\n",
      "0.0021976325660943985\n",
      "0.0010320015717297792\n",
      "0.04176156595349312\n",
      "0.00270382734015584\n",
      "0.0006366852903738618\n",
      "0.08932700008153915\n",
      "0.0005440843524411321\n",
      "0.0007318103453144431\n",
      "0.10262687504291534\n",
      "0.0016381139867007732\n",
      "0.01692376658320427\n",
      "0.0581575483083725\n",
      "0.0044325836934149265\n",
      "0.0059224385768175125\n",
      "4.4415268348529935e-05\n",
      "0.0034848377108573914\n",
      "0.006000964902341366\n",
      "0.0031102404464036226\n",
      "0.01126875076442957\n",
      "0.016426246613264084\n",
      "0.6659423112869263\n",
      "0.005827837157994509\n",
      "0.013563237152993679\n",
      "0.6142989993095398\n",
      "0.01971157267689705\n",
      "0.002808562247082591\n",
      "0.0007413291605189443\n",
      "0.006700942292809486\n",
      "0.0017778250621631742\n",
      "0.2990542948246002\n",
      "0.0011786662507802248\n",
      "0.041741035878658295\n",
      "6.0010173910995945e-05\n",
      "0.04611373692750931\n",
      "0.008022184483706951\n",
      "0.004148202482610941\n",
      "0.04251734912395477\n",
      "0.018459420651197433\n",
      "0.10204336047172546\n",
      "0.0003439310530666262\n",
      "0.02574816532433033\n",
      "0.009061858057975769\n",
      "0.0047171940095722675\n",
      "0.007723165210336447\n",
      "0.00276337843388319\n",
      "0.005682382266968489\n",
      "0.00022768935014028102\n",
      "0.07079723477363586\n",
      "0.005399046465754509\n",
      "0.000538606895133853\n",
      "0.00025455921422690153\n",
      "0.0006226666737347841\n",
      "0.0003042849129997194\n",
      "0.003964441828429699\n",
      "0.0005197263672016561\n",
      "0.001333362888544798\n",
      "0.0035495422780513763\n",
      "0.003009471110999584\n",
      "0.0027654313016682863\n",
      "0.8244199156761169\n",
      "0.00112416862975806\n",
      "0.0060986666940152645\n",
      "0.6323244571685791\n",
      "1.7099024262279272e-05\n",
      "0.0006588047253899276\n",
      "0.00402448046952486\n",
      "0.0001612950291018933\n",
      "0.0023943004198372364\n",
      "0.0921817496418953\n",
      "0.0025508676189929247\n",
      "0.006022055633366108\n",
      "0.419545978307724\n",
      "0.0039039859548211098\n",
      "0.0008522695861756802\n",
      "0.22601693868637085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(baseline_module, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `test_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0031941d2e4402af24b128ac13ddfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 256. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 8. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9961538314819336     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9961538314819336    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.9961538314819336}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(baseline_module, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "919a4ca1be5f4f5080236e503eefe8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yasin/miniforge3/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:77: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 232. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7450000643730164     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7450000643730164    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.7450000643730164}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(baseline_module, dataloaders=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(\n",
    "    max_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type               | Params\n",
      "-----------------------------------------------------\n",
      "0 | backbone      | ResNet             | 23.5 M\n",
      "1 | linear_head   | Linear             | 8.2 K \n",
      "2 | criterion     | CrossEntropyLoss   | 0     \n",
      "3 | test_accuracy | MulticlassAccuracy | 0     \n",
      "-----------------------------------------------------\n",
      "8.2 K     Trainable params\n",
      "23.5 M    Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.065    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671e743793714783b1be0698bc1813d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.434775948524475\n",
      "0.36749738454818726\n",
      "0.2770542800426483\n",
      "0.1347540020942688\n",
      "0.16318389773368835\n",
      "0.03470307216048241\n",
      "0.10208877176046371\n",
      "0.14149008691310883\n",
      "0.275717556476593\n",
      "0.05207337811589241\n",
      "0.11541955918073654\n",
      "0.03664668649435043\n",
      "0.05778340622782707\n",
      "0.05495091900229454\n",
      "0.11619449406862259\n",
      "0.04553854465484619\n",
      "0.03704789653420448\n",
      "1.306773066520691\n",
      "0.042253103107213974\n",
      "0.012536839582026005\n",
      "0.5489416718482971\n",
      "0.037668172270059586\n",
      "0.018328610807657242\n",
      "0.00971967913210392\n",
      "0.04421618953347206\n",
      "0.07888294756412506\n",
      "0.17435666918754578\n",
      "0.06947068125009537\n",
      "0.07963965088129044\n",
      "0.4594937562942505\n",
      "0.027813410386443138\n",
      "0.06717833131551743\n",
      "0.34386059641838074\n",
      "0.02532772719860077\n",
      "0.01373110618442297\n",
      "0.05727926269173622\n",
      "0.035911623388528824\n",
      "0.026287127286195755\n",
      "0.5201195478439331\n",
      "0.04163429141044617\n",
      "0.029701869934797287\n",
      "0.4964129626750946\n",
      "0.04076961427927017\n",
      "0.05044403299689293\n",
      "1.1552011966705322\n",
      "0.02943797968327999\n",
      "0.05664356052875519\n",
      "0.02241160161793232\n",
      "0.09480606764554977\n",
      "0.07930359989404678\n",
      "0.10989002883434296\n",
      "0.08047526329755783\n",
      "0.0812000185251236\n",
      "0.010783742181956768\n",
      "0.04707084223628044\n",
      "0.025534119457006454\n",
      "0.039843544363975525\n",
      "0.023606419563293457\n",
      "0.016048720106482506\n",
      "0.11436985433101654\n",
      "0.017806382849812508\n",
      "0.01997954584658146\n",
      "0.12661774456501007\n",
      "0.012678098864853382\n",
      "0.024058103561401367\n",
      "0.00014544754230882972\n",
      "0.020724551752209663\n",
      "0.003206368302926421\n",
      "0.044456541538238525\n",
      "0.011009725742042065\n",
      "0.009732539765536785\n",
      "0.267622709274292\n",
      "0.009513305500149727\n",
      "0.004908355418592691\n",
      "0.2263285219669342\n",
      "0.010037343949079514\n",
      "0.049938466399908066\n",
      "0.32613155245780945\n",
      "0.025523072108626366\n",
      "0.02849656529724598\n",
      "0.045321572571992874\n",
      "0.0377964973449707\n",
      "0.06688649207353592\n",
      "1.405078411102295\n",
      "0.02618102915585041\n",
      "0.01682189106941223\n",
      "2.144031047821045\n",
      "0.016954438760876656\n",
      "0.060540225356817245\n",
      "0.1634630709886551\n",
      "0.06388237327337265\n",
      "0.12634983658790588\n",
      "0.6350570917129517\n",
      "0.10486137121915817\n",
      "0.06268564611673355\n",
      "1.5034759044647217\n",
      "0.04833562672138214\n",
      "0.04179612919688225\n",
      "0.08195105940103531\n",
      "0.011163437739014626\n",
      "0.0482550784945488\n",
      "1.0285347700119019\n",
      "0.04911554604768753\n",
      "0.09012272953987122\n",
      "0.15751710534095764\n",
      "0.09453008323907852\n",
      "0.08208387345075607\n",
      "1.1588835716247559\n",
      "0.037941545248031616\n",
      "0.059879034757614136\n",
      "3.643527030944824\n",
      "0.05290507152676582\n",
      "0.07643583416938782\n",
      "0.11600760370492935\n",
      "0.06781961023807526\n",
      "0.04280616343021393\n",
      "2.368262767791748\n",
      "0.02875985950231552\n",
      "0.0660809800028801\n",
      "0.8258318305015564\n",
      "0.017209388315677643\n",
      "0.032999783754348755\n",
      "0.051718611270189285\n",
      "0.01820523291826248\n",
      "0.005465849302709103\n",
      "0.005084748845547438\n",
      "0.011496390216052532\n",
      "0.027812818065285683\n",
      "0.12189371138811111\n",
      "0.013687542639672756\n",
      "0.00998095516115427\n",
      "0.06676439195871353\n",
      "0.012108860537409782\n",
      "0.02683384157717228\n",
      "0.3275420367717743\n",
      "0.005366409197449684\n",
      "0.018144553527235985\n",
      "0.005566416308283806\n",
      "0.03603552281856537\n",
      "0.008368562906980515\n",
      "0.00012122662155888975\n",
      "0.028567248955368996\n",
      "0.010248908773064613\n",
      "0.0007701910217292607\n",
      "0.018301300704479218\n",
      "0.011259832419455051\n",
      "0.023687327280640602\n",
      "0.013539552688598633\n",
      "0.004045799840241671\n",
      "0.004684440791606903\n",
      "0.004908302333205938\n",
      "0.022190211340785027\n",
      "0.04897882789373398\n",
      "0.003726113820448518\n",
      "0.005534037947654724\n",
      "0.004673337563872337\n",
      "0.0025378880091011524\n",
      "0.003020303091034293\n",
      "0.00019159403746016324\n",
      "0.0009528459049761295\n",
      "0.00274295755662024\n",
      "0.021846655756235123\n",
      "0.0019490648992359638\n",
      "0.00452027004212141\n",
      "0.9902475476264954\n",
      "0.0013953415909782052\n",
      "0.003081397619098425\n",
      "0.00017866193957161158\n",
      "0.0014867386780679226\n",
      "0.017748471349477768\n",
      "0.008035344071686268\n",
      "0.016428975388407707\n",
      "0.03453918173909187\n",
      "0.00119643728248775\n",
      "0.040045253932476044\n",
      "0.034717995673418045\n",
      "0.5712443590164185\n",
      "0.010125456377863884\n",
      "0.008766153827309608\n",
      "0.0006273926701396704\n",
      "0.0018476308323442936\n",
      "0.0024775350466370583\n",
      "0.3908624053001404\n",
      "0.0009959132876247168\n",
      "0.005686161573976278\n",
      "0.0012954366393387318\n",
      "0.014567009173333645\n",
      "0.001128034433349967\n",
      "0.4176024794578552\n",
      "0.03399355337023735\n",
      "0.005112146493047476\n",
      "0.00223233038559556\n",
      "0.011747147887945175\n",
      "0.03131882846355438\n",
      "1.1200096607208252\n",
      "0.009303255937993526\n",
      "0.07026602327823639\n",
      "8.241085015470162e-05\n",
      "0.041681814938783646\n",
      "0.022365182638168335\n",
      "0.00021143356570973992\n",
      "0.047221288084983826\n",
      "0.04749409109354019\n",
      "0.05019443482160568\n",
      "0.02696593664586544\n",
      "0.1004151925444603\n",
      "0.006721600890159607\n",
      "0.058927830308675766\n",
      "0.046984653919935226\n",
      "0.004052997101098299\n",
      "0.020560871809720993\n",
      "0.053312160074710846\n",
      "0.09704214334487915\n",
      "0.011247524991631508\n",
      "0.03275830298662186\n",
      "0.00014988942712079734\n",
      "0.029087089002132416\n",
      "0.011686720885336399\n",
      "1.0178134441375732\n",
      "0.015554466284811497\n",
      "0.031028971076011658\n",
      "0.21855486929416656\n",
      "0.018286066129803658\n",
      "0.02248762920498848\n",
      "8.10184283182025e-05\n",
      "0.004585694521665573\n",
      "0.01758107729256153\n",
      "2.137831211090088\n",
      "0.007195891812443733\n",
      "0.008219482377171516\n",
      "0.4962058663368225\n",
      "0.014778352342545986\n",
      "0.01981676183640957\n",
      "1.1554932594299316\n",
      "0.04559685289859772\n",
      "0.06091228872537613\n",
      "0.19597570598125458\n",
      "0.015857065096497536\n",
      "0.011823444627225399\n",
      "0.020026102662086487\n",
      "0.006719105876982212\n",
      "0.016530711203813553\n",
      "0.8637826442718506\n",
      "0.007029685657471418\n",
      "0.00903703086078167\n",
      "0.010385166853666306\n",
      "0.03831416741013527\n",
      "0.00303797610104084\n",
      "0.003808446228504181\n",
      "0.011006304994225502\n",
      "0.019820276647806168\n",
      "0.4857000410556793\n",
      "0.012293320149183273\n",
      "0.023173538967967033\n",
      "0.057264573872089386\n",
      "0.03865940123796463\n",
      "0.056296899914741516\n",
      "1.0109877586364746\n",
      "0.03715456649661064\n",
      "0.06708601117134094\n",
      "0.22445866465568542\n",
      "0.08466361463069916\n",
      "0.023210851475596428\n",
      "0.03291408717632294\n",
      "0.04242980480194092\n",
      "0.07678182423114777\n",
      "0.0049203732050955296\n",
      "0.01865505799651146\n",
      "0.036893848329782486\n",
      "0.08625861257314682\n",
      "0.03287559375166893\n",
      "0.01083397213369608\n",
      "0.0008782076183706522\n",
      "0.0069386912509799\n",
      "0.0034822733141481876\n",
      "0.0035745841450989246\n",
      "0.004123064689338207\n",
      "0.005496434401720762\n",
      "0.00033776421332731843\n",
      "0.007302531041204929\n",
      "0.01910274662077427\n",
      "0.07806801050901413\n",
      "0.0033822935074567795\n",
      "0.002412662608548999\n",
      "0.016150273382663727\n",
      "0.000448661798145622\n",
      "0.006475668400526047\n",
      "0.4339526891708374\n",
      "0.0008478210074827075\n",
      "0.00131042895372957\n",
      "0.7085012197494507\n",
      "0.0009755876963026822\n",
      "0.001718699000775814\n",
      "0.0330374613404274\n",
      "0.002728444989770651\n",
      "0.005404121242463589\n",
      "0.0005510923801921308\n",
      "0.018574243411421776\n",
      "0.023876311257481575\n",
      "1.285996913909912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(mixstyle_module, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96eef7a742644498bc812fb1f7514ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.9884615540504456     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.9884615540504456    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.9884615540504456}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(mixstyle_module, dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570984cd2d6c402da4130be8bc25793a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8180000185966492     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8180000185966492    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.8180000185966492}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(mixstyle_module, dataloaders=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
